{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f2827a2-1d19-4bd3-b73c-8513478b58ca",
   "metadata": {},
   "source": [
    "# NanoGPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e89d4d6-6c46-4208-9e27-92de6219fbe7",
   "metadata": {},
   "source": [
    "My implementation of decoder only transformer based on Andrej Karpathy's model. This model generates Shakespeare-like text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3163f352-902f-4564-b29b-c5f962107d80",
   "metadata": {},
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8d4b84c4-124f-4751-9ac0-579aef2f5675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45b7c50b-a4d1-456b-b0e0-bd733da7bf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set torch device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "541224ea-c867-4e92-968e-9661eb70cce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data constants\n",
    "DATASET_LINK='https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94b648d0-5e10-4360-bd88-13a7eafc5566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f8adb25d410>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set torch seed\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e4176b-e3e8-41fa-be8f-abbbd52dd1d7",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af0aeb1-941d-4172-8f62-9533041dbafe",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a465cef-42df-4f95-a800-c0fe51968c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-06-15 21:33:11--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1115394 (1.1M) [text/plain]\n",
      "Saving to: ‘input.txt’\n",
      "\n",
      "input.txt           100%[===================>]   1.06M  --.-KB/s    in 0.06s   \n",
      "\n",
      "2024-06-15 21:33:11 (17.0 MB/s) - ‘input.txt’ saved [1115394/1115394]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download dataset\n",
    "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt -O input.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a475821-d24c-453e-bcab-d2bd4127b2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read dataset\n",
    "raw_text = ''\n",
    "with open('./input.txt','r') as f:\n",
    "    raw_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1462a683-9abb-4606-bb1d-1ce9799c8b5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1115394"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data size\n",
    "len(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "048b5ad8-65d4-4337-a61e-649e621e9fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You\n"
     ]
    }
   ],
   "source": [
    "# Check data sample\n",
    "print(raw_text[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02fd462-71dc-422b-a982-e075c98c7d67",
   "metadata": {},
   "source": [
    "### Build Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7daea490-6988-4353-b66b-69bf9c62fa03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique characters\n",
    "vocab = sorted(list(set(raw_text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4c7d132-df28-42f2-87df-9ac0b9085347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get vocab size\n",
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a14b6a88-0559-43d6-aaeb-35cf91c692a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size:\n",
      "65\n",
      "Vocab list:\n",
      "['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "# Print vocab and vocab size\n",
    "print(f'Vocab size:\\n{vocab_size}')\n",
    "print(f'Vocab list:\\n{vocab}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aaf56b25-f14d-4b7e-a45e-56eb99a89037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vocab mappings\n",
    "token_to_i = {token:i for i,token in enumerate(vocab)}\n",
    "i_to_token = {i:token for i,token in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a0296fb-a7c5-4d6e-a692-efd21b222d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder util\n",
    "def encode(s):\n",
    "    return [token_to_i[token] for token in s]\n",
    "\n",
    "# Decoder util\n",
    "def decode(s):\n",
    "    return ''.join([i_to_token[token] for token in s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "869fa619-7e78-43f2-a463-5956082382f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17, 52, 41, 53, 42, 43, 56, 1, 39, 52, 42, 1, 42, 43, 41, 53, 42, 43, 56, 1, 58, 43, 57, 58]\n",
      "Encoder and decoder test\n"
     ]
    }
   ],
   "source": [
    "# Test encoder and decoders\n",
    "print(encode(\"Encoder and decoder test\"))\n",
    "print(decode(encode(\"Encoder and decoder test\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e259376-5daf-4c2f-801f-499fa2c28741",
   "metadata": {},
   "source": [
    "### Tokenize Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35f3fd03-95cd-4436-9373-e24618c8b7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize data\n",
    "tokenized_text = encode(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "abeaa42b-b113-4610-983d-978888e4e483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to tensor\n",
    "data = torch.tensor(tokenized_text, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b86cd35-e559-4406-98db-247c0d5c1f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115394])\n",
      "torch.int64\n",
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
      "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
      "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59])\n"
     ]
    }
   ],
   "source": [
    "# Check data\n",
    "print(data.shape)\n",
    "print(data.dtype)\n",
    "print(data[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d57bcf-8958-46c7-b0a3-0cf23b430ddf",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c15b8d3e-6dc3-4219-942b-cf79da319fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index for splitting\n",
    "split_index = int(data.shape[0] * 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d24d4266-ed6f-4539-8fca-ec1e377cc75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate train and test data\n",
    "train_data = data[:split_index]\n",
    "test_data = data[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "171631ce-8f79-43e9-af48-7964191f704c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([892315])\n",
      "torch.Size([223079])\n"
     ]
    }
   ],
   "source": [
    "# Print train/test sizes\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fa3a8b-772d-4207-9a88-eff1db25a7af",
   "metadata": {},
   "source": [
    "### Data Batch Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dfefef87-82ca-420f-8d8e-b5c2cde2e86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility to get batch\n",
    "def _get_batch(split, batch_size, block_size):\n",
    "    data_tensor = train_data if split == 'train' else test_data;\n",
    "    block_indices = torch.randint(len(data_tensor) - block_size, (batch_size,))\n",
    "    x = torch.stack([data_tensor[i:i+block_size] for i in block_indices])\n",
    "    y = torch.stack([data_tensor[i+1:i+1+block_size] for i in block_indices])\n",
    "    return x.to(device), y.to(device)\n",
    "\n",
    "# Utility to get train batches\n",
    "def get_train_batch(batch_size, block_size):\n",
    "    return _get_batch('train', batch_size, block_size)\n",
    "\n",
    "# Utility to get train batches\n",
    "def get_test_batch(batch_size, block_size):\n",
    "    return _get_batch('test', batch_size, block_size)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c810871d-4af2-4d42-b072-9f71277d3ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 16])\n",
      "torch.Size([4, 16])\n",
      "tensor([[61, 47, 50, 50, 12,  0,  0, 28, 27, 24, 21, 36, 17, 26, 17, 31],\n",
      "        [43,  1, 51, 47, 45, 46, 58,  1, 39, 41, 58,  1, 58, 46, 43,  1],\n",
      "        [56,  1, 53, 44,  1, 58, 56, 47, 40, 59, 52, 43, 57,  1, 58, 46],\n",
      "        [ 1, 39,  1, 58, 39, 50, 50,  1, 44, 43, 50, 50, 53, 61,  1, 53]],\n",
      "       device='cuda:0')\n",
      "tensor([[47, 50, 50, 12,  0,  0, 28, 27, 24, 21, 36, 17, 26, 17, 31, 10],\n",
      "        [ 1, 51, 47, 45, 46, 58,  1, 39, 41, 58,  1, 58, 46, 43,  1, 61],\n",
      "        [ 1, 53, 44,  1, 58, 56, 47, 40, 59, 52, 43, 57,  1, 58, 46, 39],\n",
      "        [39,  1, 58, 39, 50, 50,  1, 44, 43, 50, 50, 53, 61,  1, 53, 44]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Test batch generator\n",
    "_x, _y = get_train_batch(4,16)\n",
    "print(_x.shape)\n",
    "print(_y.shape)\n",
    "print(_x)\n",
    "print(_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87027a4-e53d-46f7-a0b8-10136f6bd428",
   "metadata": {},
   "source": [
    "## Transformer Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987519b5-d4af-4d97-8d42-be2861332372",
   "metadata": {},
   "source": [
    "#### Layer Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9c7dd9f3-bd29-4d52-bc15-2c5852dfdfa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layer norm\n",
    "class LayerNorm(nn.Module):\n",
    "\n",
    "    # Constructor\n",
    "    def __init__(self, dim, eps=1e-5):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.gamma = nn.Parameter(torch.ones(dim))\n",
    "        self.beta = nn.Parameter(torch.zeros(dim))\n",
    "\n",
    "    # Call method\n",
    "    def forward(self, x):\n",
    "        x_mean = x.mean(1, keepdim=True)\n",
    "        x_var = x.var(1, keepdim=True)\n",
    "        out = (x - x_mean) / torch.sqrt(x_var + self.eps)\n",
    "        out = self.gamma * out + self.beta\n",
    "        self.out = out\n",
    "        return self.out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa01cff-28b6-4613-ac45-7f96d2599f03",
   "metadata": {},
   "source": [
    "Test layer norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a25a3907-38ef-4e83-be8f-fce513236310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 100])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xt = torch.randn(16, 100)\n",
    "ln = LayerNorm(100)\n",
    "xt = ln(xt)\n",
    "xt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5145461a-c6a6-4623-980e-2fb13665ee8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-2.0862e-09, grad_fn=<MeanBackward0>),\n",
       " tensor(1.0000, grad_fn=<StdBackward0>))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xt[0,:].mean(), xt[0,:].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5ce64660-d054-414a-844b-b0f3f390659c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
       "       grad_fn=<StdBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xt.std(dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f21c4cd-735b-43ad-b4d6-5ec196848a7a",
   "metadata": {},
   "source": [
    "#### Multi-Head Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ad47b089-001b-4401-8333-20a5ebfa2771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer head modue\n",
    "class Head(nn.Module):\n",
    "\n",
    "    # Constructor\n",
    "    def __init__(self, block_size, n_embed, head_size, dropout):\n",
    "        super().__init__()\n",
    "\n",
    "        # Private properties\n",
    "        self.head_size = head_size\n",
    "\n",
    "        # K,Q,V layers\n",
    "        self.key = nn.Linear(n_embed, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embed, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embed, head_size, bias=False)\n",
    "\n",
    "        # Triangular matrix buffer\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    # Forward method\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Get dims\n",
    "        B,T,embed = x.shape\n",
    "\n",
    "        # Calculate K,Q,V\n",
    "        k = self.key(x) # (B,T,e) => (B,T,h)\n",
    "        q = self.query(x) # (B,T,e) => (B,T,h)\n",
    "        v = self.value(x) # (B,T,e) => (B,T,h)\n",
    "\n",
    "        # Calculate self attention matrix\n",
    "        attn = (q @ k.transpose(-2,-1)) * np.sqrt(self.head_size) # (B,T,h) @ (B,h,T) => (B,T,T)\n",
    "        attn = attn.masked_fill(self.tril[:T,:T] == 0, float('-inf')) # (B,T,T)\n",
    "        attn = F.softmax(attn, dim=-1) # B,T,T\n",
    "        attn = self.dropout(attn)\n",
    "\n",
    "        # Aggregate values based on attention\n",
    "        out = attn @ v\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "68674800-02b9-4234-8ee3-71f8a493b54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi head attention module\n",
    "class MultiHeadAttention(nn.Module):\n",
    "\n",
    "    # Constructor\n",
    "    def __init__(self, block_size, n_embed, n_heads, head_size, dropout):\n",
    "        super().__init__()\n",
    "\n",
    "        # Add multiple heads\n",
    "        self.heads = [Head(block_size, n_embed, head_size, dropout).to(device) for _ in range(n_heads)]\n",
    "\n",
    "        # Linear projection\n",
    "        self.linear = nn.Linear(n_heads * head_size, n_embed)\n",
    "\n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    # Forward method\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Concat results from all heads and return\n",
    "        out = torch.cat([head(x) for head in self.heads], dim=-1)\n",
    "        out = self.dropout(self.linear(out))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da1bdc2-b600-44e2-8b5a-01a8fa9282fb",
   "metadata": {},
   "source": [
    "#### Feed forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3244a49a-4c3c-4879-a927-5f62bda5c9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feed forward block\n",
    "class FeedForward(nn.Module):\n",
    "\n",
    "    # Constructor\n",
    "    def __init__(self, dim, dropout):\n",
    "        super().__init__()\n",
    "        self.nn = nn.Sequential(\n",
    "            nn.Linear(dim, 4*dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4*dim, dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "    # Forward method\n",
    "    def forward(self, x):\n",
    "        return self.nn(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1364f6-2eb2-466e-975d-d69e45d5ab59",
   "metadata": {},
   "source": [
    "#### Transformer Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2ac4ee14-671a-4689-91e0-11eca0837a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer's decoder block (No need of encoder block in GPT)\n",
    "class DecoderBlock(nn.Module):\n",
    "\n",
    "    # Constructor\n",
    "    def __init__(self, block_size, n_embed, n_heads, dropout):\n",
    "        super().__init__()\n",
    "        head_size = n_embed // n_heads\n",
    "        \n",
    "        # Self attention and feed forward layers\n",
    "        self.self_attn = MultiHeadAttention(block_size, n_embed, n_heads, head_size, dropout)\n",
    "        self.ff = FeedForward(n_embed, dropout)\n",
    "\n",
    "        # layer norm\n",
    "        self.ln_1 = nn.LayerNorm(n_embed)\n",
    "        self.ln_2 = nn.LayerNorm(n_embed)\n",
    "\n",
    "    # Forward method\n",
    "    def forward(self,x):\n",
    "        x = x + self.self_attn(self.ln_1(x))\n",
    "        x = x + self.ff(self.ln_2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd82079-c1c4-4581-86b3-2be6c6c4a1e5",
   "metadata": {},
   "source": [
    "#### Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6679ff25-7f38-43c7-bb11-c1b13a6f6579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer model class\n",
    "class TransformerModel(nn.Module):\n",
    "\n",
    "    # Constructor\n",
    "    def __init__(self, block_size, n_embed, n_heads, n_layers, dropout):\n",
    "        super().__init__()\n",
    "\n",
    "        # Token embedding\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embed)\n",
    "\n",
    "        # Positional embedding\n",
    "        self.positional_embedding_table = nn.Embedding(block_size, n_embed)\n",
    "\n",
    "        # Self attention layer\n",
    "        self.blocks = nn.Sequential(*[DecoderBlock(block_size=block_size, n_embed=n_embed, n_heads=n_heads, dropout=dropout) for _ in range(n_layers)])\n",
    "        self.ln = nn.LayerNorm(n_embed)\n",
    "        \n",
    "        # Linear layer\n",
    "        self.lm_head = nn.Linear(n_embed, vocab_size)\n",
    "\n",
    "    # Forward method\n",
    "    def forward(self, x, targets=None):\n",
    "    \n",
    "        # x is (B,T) and targets is also (B,T)\n",
    "        B,T = x.shape\n",
    "\n",
    "        # Apply token and positional embeddings\n",
    "        tok_embedding = self.token_embedding_table(x) # embeddings will be (B,T,n_embed)\n",
    "        pos_embedding = self.positional_embedding_table(torch.arange(T, device=device)) # embeddings will be (T,n_embed)\n",
    "        x = tok_embedding + pos_embedding # (B,T,n_embed)\n",
    "        \n",
    "        # Apply decoder blocks and layer norm\n",
    "        x = self.blocks(x) # (B,T,n_embed)\n",
    "        x = self.ln(x) # (B,T,n_embed)\n",
    "\n",
    "        # Get logits\n",
    "        logits = self.lm_head(x) # logits will be (B,T,vocab_size)\n",
    "\n",
    "        # Get loss\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B,T,C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        # Return\n",
    "        return logits, loss\n",
    "\n",
    "    # Generate method to generate next tokens\n",
    "    def generate(self, x, max_tokens):\n",
    "\n",
    "        # Loop and generate tokens\n",
    "        for _ in range(max_tokens):\n",
    "\n",
    "            # Get last block\n",
    "            last_block = x[:,-block_size:]\n",
    "\n",
    "            # Get predictions\n",
    "            logits, loss = self(last_block) # logits: (B,T,vocab_size)\n",
    "\n",
    "            # Get generated token and append to x\n",
    "            logits = logits[:,-1,:] # (B,vocab_size)\n",
    "            probs = F.softmax(logits, dim=-1) # (B,vocab_size)\n",
    "            next_token = torch.multinomial(probs, num_samples=1) # (B,1)\n",
    "            x = torch.cat((x, next_token), dim=1) # (B,T+1)\n",
    "\n",
    "        # Return generated text\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ba6578-7073-4382-9505-ccda0e0b11d7",
   "metadata": {},
   "source": [
    "Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7157b603-473c-4499-8a7c-62fb82c9709b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 65])\n"
     ]
    }
   ],
   "source": [
    "model = TransformerModel(\n",
    "    n_embed = 256,\n",
    "    block_size = 256,\n",
    "    n_heads = 8,\n",
    "    n_layers = 8,\n",
    "    dropout=0.2\n",
    ")\n",
    "model.to(device)\n",
    "logits, loss = model(_x.to(device),_y.to(device))\n",
    "print(logits.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84843511-241d-4602-8aff-7d592dede115",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92f670f-cb69-4f22-a3ec-31b4e5372157",
   "metadata": {},
   "source": [
    "#### Training Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "01f4551b-f9d1-462d-8538-f3e783fe3929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "eval_iters = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8b6f9c92-aa5e-43b1-ae33-63712a5f8738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to estimate loss based on random batches\n",
    "@torch.no_grad()\n",
    "def estimate_loss(m, batch_size, block_size):\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    train_losses = torch.zeros(eval_iters)\n",
    "    val_losses = torch.zeros(eval_iters)\n",
    "    for i in range(eval_iters):\n",
    "        x, y = get_train_batch(batch_size, block_size)\n",
    "        logits, loss = m(x, y)\n",
    "        train_losses[i] = loss.item()\n",
    "        x, y = get_test_batch(batch_size, block_size)\n",
    "        logits, loss = m(x, y)\n",
    "        val_losses[i] = loss.item()\n",
    "    return train_losses.mean(), val_losses.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "79cbc755-d17f-4d95-91c0-a99e2dca1b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "def train(model, max_steps, eval_interval, loss_list, init_step=0):\n",
    "    model.train()\n",
    "\n",
    "    # Loop steps\n",
    "    for step in range(max_steps):\n",
    "    \n",
    "        # Get sample batch\n",
    "        x, y = get_train_batch(batch_size, block_size)\n",
    "    \n",
    "        # Evaluate\n",
    "        logits, loss = model(x.to(device),y.to(device))\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        # Estimate and print loss\n",
    "        if(step == 0 or (step + 1) % eval_interval == 0 or step == max_steps - 1):\n",
    "            train_loss, val_loss = estimate_loss(model, batch_size, block_size)\n",
    "            loss_list.append({\n",
    "                'step': init_step+step,\n",
    "                'train_loss': train_loss,\n",
    "                'val_loss': val_loss\n",
    "            })\n",
    "            print(f'Step {init_step+step+1:<4}: train loss [{train_loss:.4f}], val loss:[{val_loss:.4f}] ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464c9180-b452-48af-9408-0f0619fe7ad2",
   "metadata": {},
   "source": [
    "#### Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4c8da3cb-e187-457b-8a62-665a3826fd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model params\n",
    "batch_size = 64\n",
    "block_size = 256\n",
    "learning_rate = 5e-4\n",
    "embedding_dim = 256\n",
    "num_heads = 8\n",
    "num_layers = 6\n",
    "dropout = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d10d1ae3-bfb2-4a52-a2b4-9fd4b260ad69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerModel(\n",
       "  (token_embedding_table): Embedding(65, 256)\n",
       "  (positional_embedding_table): Embedding(256, 256)\n",
       "  (blocks): Sequential(\n",
       "    (0): DecoderBlock(\n",
       "      (self_attn): MultiHeadAttention(\n",
       "        (linear): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (nn): Sequential(\n",
       "          (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (1): DecoderBlock(\n",
       "      (self_attn): MultiHeadAttention(\n",
       "        (linear): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (nn): Sequential(\n",
       "          (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (2): DecoderBlock(\n",
       "      (self_attn): MultiHeadAttention(\n",
       "        (linear): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (nn): Sequential(\n",
       "          (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (3): DecoderBlock(\n",
       "      (self_attn): MultiHeadAttention(\n",
       "        (linear): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (nn): Sequential(\n",
       "          (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (4): DecoderBlock(\n",
       "      (self_attn): MultiHeadAttention(\n",
       "        (linear): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (nn): Sequential(\n",
       "          (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (5): DecoderBlock(\n",
       "      (self_attn): MultiHeadAttention(\n",
       "        (linear): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (nn): Sequential(\n",
       "          (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (ln): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "  (lm_head): Linear(in_features=256, out_features=65, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model\n",
    "model = TransformerModel(\n",
    "    n_embed = embedding_dim,\n",
    "    block_size = block_size,\n",
    "    n_heads = num_heads,\n",
    "    n_layers = num_layers,\n",
    "    dropout=dropout\n",
    ")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9c07b076-8b9f-4131-a617-14f89789bba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training params\n",
    "eval_iters = 100\n",
    "eval_interval = 100\n",
    "learning_rate = 2e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e2672b54-be19-4a77-8ebd-767b72ea6acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66b66d2-be6d-471a-baf8-3473ae6f87b4",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ebe810fa-7b12-4723-bc41-9739e2d80a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss data\n",
    "loss_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d34fe14b-29fe-4aee-adc0-e9d30ece22da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1   : train loss [4.0304], val loss:[4.0382] \n",
      "Step 100 : train loss [2.5627], val loss:[2.5893] \n",
      "Step 200 : train loss [2.4965], val loss:[2.5333] \n",
      "Step 300 : train loss [2.4738], val loss:[2.5147] \n",
      "Step 400 : train loss [2.4607], val loss:[2.5000] \n",
      "Step 500 : train loss [2.4537], val loss:[2.4966] \n",
      "Step 600 : train loss [2.4439], val loss:[2.4900] \n",
      "Step 700 : train loss [2.4333], val loss:[2.4828] \n",
      "Step 800 : train loss [2.4194], val loss:[2.4739] \n",
      "Step 900 : train loss [2.4051], val loss:[2.4602] \n",
      "Step 1000: train loss [2.3843], val loss:[2.4393] \n",
      "Step 1100: train loss [2.3630], val loss:[2.4241] \n",
      "Step 1200: train loss [2.3323], val loss:[2.4024] \n",
      "Step 1300: train loss [2.2941], val loss:[2.3667] \n",
      "Step 1400: train loss [2.2572], val loss:[2.3352] \n",
      "Step 1500: train loss [2.2225], val loss:[2.3089] \n",
      "Step 1600: train loss [2.1725], val loss:[2.2639] \n",
      "Step 1700: train loss [2.1313], val loss:[2.2224] \n",
      "Step 1800: train loss [2.0986], val loss:[2.2023] \n",
      "Step 1900: train loss [2.0708], val loss:[2.1714] \n",
      "Step 2000: train loss [2.0419], val loss:[2.1598] \n",
      "Step 2100: train loss [2.0118], val loss:[2.1340] \n",
      "Step 2200: train loss [1.9914], val loss:[2.1102] \n",
      "Step 2300: train loss [1.9659], val loss:[2.0903] \n",
      "Step 2400: train loss [1.9419], val loss:[2.0697] \n",
      "Step 2500: train loss [1.9170], val loss:[2.0578] \n",
      "Step 2600: train loss [1.8966], val loss:[2.0425] \n",
      "Step 2700: train loss [1.8812], val loss:[2.0315] \n",
      "Step 2800: train loss [1.8587], val loss:[2.0194] \n",
      "Step 2900: train loss [1.8363], val loss:[2.0112] \n",
      "Step 3000: train loss [1.8248], val loss:[1.9975] \n",
      "Step 3100: train loss [1.8003], val loss:[1.9737] \n",
      "Step 3200: train loss [1.7859], val loss:[1.9678] \n",
      "Step 3300: train loss [1.7717], val loss:[1.9553] \n",
      "Step 3400: train loss [1.7569], val loss:[1.9397] \n",
      "Step 3500: train loss [1.7392], val loss:[1.9276] \n",
      "Step 3600: train loss [1.7246], val loss:[1.9167] \n",
      "Step 3700: train loss [1.7073], val loss:[1.9038] \n",
      "Step 3800: train loss [1.7015], val loss:[1.9047] \n",
      "Step 3900: train loss [1.6855], val loss:[1.8871] \n",
      "Step 4000: train loss [1.6711], val loss:[1.8802] \n",
      "Step 4100: train loss [1.6654], val loss:[1.8744] \n",
      "Step 4200: train loss [1.6565], val loss:[1.8677] \n",
      "Step 4300: train loss [1.6457], val loss:[1.8540] \n",
      "Step 4400: train loss [1.6322], val loss:[1.8567] \n",
      "Step 4500: train loss [1.6218], val loss:[1.8432] \n",
      "Step 4600: train loss [1.6109], val loss:[1.8477] \n",
      "Step 4700: train loss [1.6071], val loss:[1.8312] \n",
      "Step 4800: train loss [1.5972], val loss:[1.8265] \n",
      "Step 4900: train loss [1.5912], val loss:[1.8246] \n",
      "Step 5000: train loss [1.5753], val loss:[1.8119] \n"
     ]
    }
   ],
   "source": [
    "# Train 5000 steps\n",
    "train(model=model, max_steps=5000, eval_interval=eval_interval, loss_list=loss_data, init_step=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7037c567-f16a-4d1f-86f1-1490c2a7c40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save checkpoint\n",
    "torch.save(model, './model_5k_steps_2e-4_lr.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0c9ff4f6-5177-46bd-98d3-8f9420d6f158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5001: train loss [1.6677], val loss:[1.9133] \n",
      "Step 5100: train loss [1.5792], val loss:[1.8192] \n",
      "Step 5200: train loss [1.5640], val loss:[1.7979] \n",
      "Step 5300: train loss [1.5558], val loss:[1.8005] \n",
      "Step 5400: train loss [1.5497], val loss:[1.7934] \n",
      "Step 5500: train loss [1.5454], val loss:[1.7962] \n",
      "Step 5600: train loss [1.5339], val loss:[1.7881] \n",
      "Step 5700: train loss [1.5330], val loss:[1.7873] \n",
      "Step 5800: train loss [1.5232], val loss:[1.7907] \n",
      "Step 5900: train loss [1.5176], val loss:[1.7812] \n",
      "Step 6000: train loss [1.5073], val loss:[1.7846] \n",
      "Step 6100: train loss [1.5068], val loss:[1.7680] \n",
      "Step 6200: train loss [1.5026], val loss:[1.7774] \n",
      "Step 6300: train loss [1.5003], val loss:[1.7631] \n",
      "Step 6400: train loss [1.4895], val loss:[1.7587] \n",
      "Step 6500: train loss [1.4891], val loss:[1.7629] \n",
      "Step 6600: train loss [1.4836], val loss:[1.7568] \n",
      "Step 6700: train loss [1.4777], val loss:[1.7575] \n",
      "Step 6800: train loss [1.4738], val loss:[1.7501] \n",
      "Step 6900: train loss [1.4658], val loss:[1.7479] \n",
      "Step 7000: train loss [1.4618], val loss:[1.7516] \n",
      "Step 7100: train loss [1.4571], val loss:[1.7420] \n",
      "Step 7200: train loss [1.4614], val loss:[1.7493] \n",
      "Step 7300: train loss [1.4506], val loss:[1.7324] \n",
      "Step 7400: train loss [1.4476], val loss:[1.7497] \n",
      "Step 7500: train loss [1.4429], val loss:[1.7328] \n"
     ]
    }
   ],
   "source": [
    "# Train 2500 more steps (Total 7500)\n",
    "train(model=model, max_steps=2500, eval_interval=eval_interval, loss_list=loss_data, init_step=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7f471989-0b5c-4646-b961-0dc8cddc8c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save checkpoint\n",
    "torch.save(model, './model_7.5k_steps_2e-4_lr.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "170c405c-25a0-4eff-8fdb-ec88a4eaf61e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 7501: train loss [1.5079], val loss:[1.7998] \n",
      "Step 7600: train loss [1.4361], val loss:[1.7311] \n",
      "Step 7700: train loss [1.4310], val loss:[1.7314] \n",
      "Step 7800: train loss [1.4293], val loss:[1.7296] \n",
      "Step 7900: train loss [1.4305], val loss:[1.7300] \n",
      "Step 8000: train loss [1.4224], val loss:[1.7230] \n",
      "Step 8100: train loss [1.4132], val loss:[1.7253] \n",
      "Step 8200: train loss [1.4157], val loss:[1.7260] \n",
      "Step 8300: train loss [1.4102], val loss:[1.7159] \n",
      "Step 8400: train loss [1.4099], val loss:[1.7244] \n",
      "Step 8500: train loss [1.4072], val loss:[1.7209] \n",
      "Step 8600: train loss [1.4039], val loss:[1.7174] \n",
      "Step 8700: train loss [1.3998], val loss:[1.7177] \n",
      "Step 8800: train loss [1.3954], val loss:[1.7157] \n",
      "Step 8900: train loss [1.3955], val loss:[1.7116] \n",
      "Step 9000: train loss [1.3910], val loss:[1.7197] \n",
      "Step 9100: train loss [1.3888], val loss:[1.7153] \n",
      "Step 9200: train loss [1.3783], val loss:[1.7092] \n",
      "Step 9300: train loss [1.3820], val loss:[1.7104] \n",
      "Step 9400: train loss [1.3762], val loss:[1.7093] \n",
      "Step 9500: train loss [1.3762], val loss:[1.7158] \n",
      "Step 9600: train loss [1.3780], val loss:[1.7170] \n",
      "Step 9700: train loss [1.3713], val loss:[1.6991] \n",
      "Step 9800: train loss [1.3691], val loss:[1.7080] \n",
      "Step 9900: train loss [1.3649], val loss:[1.7028] \n",
      "Step 10000: train loss [1.3635], val loss:[1.7094] \n"
     ]
    }
   ],
   "source": [
    "# Train 2500 more steps (Total 10000)\n",
    "train(model=model, max_steps=2500, eval_interval=eval_interval, loss_list=loss_data, init_step=7500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5d621e3d-fd2e-4d6a-8ea3-7b04f13cbcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save checkpoint\n",
    "torch.save(model, './model_10k_steps_2e-4_lr.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "83c5ad1c-14c9-403d-b4c7-a3a87af08162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f8a7d1c2150>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAGwCAYAAABVdURTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAA9hAAAPYQGoP6dpAABhEUlEQVR4nO3dd3zU9eHH8dddLrnsCwkZjIQZ9l4yFLSioFQBq1JEwUq1zmJbW0u11lHFVevAn7OKWhHFilsRkCFTQDYY2QmQwcpeN76/P77JQSSEdbnLeD8fj3uQ+34/9/1+7ksl736mxTAMAxEREZEGwhroCoiIiIj4ksKNiIiINCgKNyIiItKgKNyIiIhIg6JwIyIiIg2Kwo2IiIg0KAo3IiIi0qDYAl0Bf/N4PBw4cICoqCgsFkugqyMiIiKnwTAMCgoKaN68OVZrzW0zjS7cHDhwgOTk5EBXQ0RERM5CRkYGLVu2rLFMows3UVFRgPlwoqOjA1wbEREROR35+fkkJyd7f4/XpNGFm8quqOjoaIUbERGReuZ0hpRoQLGIiIg0KAo3IiIi0qAo3IiIiEiD0ujG3IiISMPhdrtxOp2Brob4SEhIyCmneZ8OhRsREal3DMMgKyuL3NzcQFdFfMhqtdKmTRtCQkLO6ToKNyIiUu9UBpuEhATCw8O1KGsDULnIbmZmJikpKef0d6pwIyIi9Yrb7fYGm7i4uEBXR3woPj6eAwcO4HK5CA4OPuvraECxiIjUK5VjbMLDwwNcE/G1yu4ot9t9TtdRuBERkXpJXVENj6/+ThVuREREpEFRuBEREZEGReFGRESkHmvdujXPPvvsaZdftGgRFoulQU+jV7jxFVcZ5O0zXyIiIj9jsVhqfD344INndd3Vq1dzyy23nHb5wYMHk5mZicPhOKv71QeaCu4jZelrsL99OU5HG4L/sD7Q1RERkTomMzPT+/P777/PAw88QFpamvdYZGSk92fDMHC73dhsp/41HR8ff0b1CAkJISkp6Yw+U9+o5cZHdh4pB+BwfmGAayIi0vgYhkFxuSsgL8MwTquOSUlJ3pfD4cBisXjf//jjj0RFRfHVV1/Rt29f7HY7S5cuZefOnYwePZrExEQiIyPp378/8+fPr3Ldn3dLWSwWXn/9dcaOHUt4eDipqal8+umn3vM/75aaMWMGMTExzJ07l86dOxMZGcnIkSOrhDGXy8Xvf/97YmJiiIuL495772XSpEmMGTPmrP/OalOdabl5/PHHmTp1KlOmTKmx73D27Nn8/e9/Z8+ePaSmpvLEE09w+eWX+6+iJxEUHAqAzXAFuCYiIo1PidNNlwfmBuTeWx8eQXiIb36d/vWvf+Xpp5+mbdu2NGnShIyMDC6//HIeffRR7HY7b7/9NldccQVpaWmkpKSc9DoPPfQQTz75JE899RQvvPACEyZMYO/evcTGxlZbvri4mKeffpp33nkHq9XK9ddfzz333MO7774LwBNPPMG7777Lm2++SefOnXnuuef4+OOPueiii3zyvX2tTrTcrF69mldeeYUePXrUWG758uWMHz+eyZMns27dOsaMGcOYMWPYvHmzn2p6crZgOwDBaAM3ERE5Ow8//DCXXHIJ7dq1IzY2lp49e/K73/2Obt26kZqayiOPPEK7du2qtMRU58Ybb2T8+PG0b9+exx57jMLCQr7//vuTlnc6nbz88sv069ePPn36cOedd7JgwQLv+RdeeIGpU6cyduxYOnXqxPTp04mJifHV1/a5gLfcFBYWMmHCBF577TX++c9/1lj2ueeeY+TIkfz5z38G4JFHHmHevHlMnz6dl19+2R/VPakghRsRkYAJCw5i68MjAnZvX+nXr1+V94WFhTz44IN88cUXZGZm4nK5KCkpIT09vcbrHN9YEBERQXR0NDk5OSctHx4eTrt27bzvmzVr5i2fl5dHdnY2AwYM8J4PCgqib9++eDyeM/p+/hLwcHPHHXcwatQohg8ffspws2LFCv74xz9WOTZixAg+/vjjk36mrKyMsrIy7/v8/Pxzqu/JBIdUhBt1S4mI+J3FYvFZ11AgRUREVHl/zz33MG/ePJ5++mnat29PWFgYV199NeXl5TVe5+f7MlkslhqDSHXlT3csUV0U0G6pWbNm8cMPPzBt2rTTKp+VlUViYmKVY4mJiWRlZZ30M9OmTcPhcHhfycnJ51Tnk7FVhhuLG+rx/yBERKTuWLZsGTfeeCNjx46le/fuJCUlsWfPHr/WweFwkJiYyOrVq73H3G43P/zwg1/rcSYCFm4yMjKYMmUK7777LqGhobV2n6lTp5KXl+d9ZWRk1Mp9bCHHvoPhKquhpIiIyOlJTU3lo48+Yv369WzYsIHrrrsuIF1Bd911F9OmTeOTTz4hLS2NKVOmcPTo0Tq7v1fA2vDWrl1LTk4Offr08R5zu90sWbKE6dOnU1ZWRlBQ1X7MpKQksrOzqxzLzs6ucb6+3W7Hbrf7tvLVqOyWAnCWlxESXHuBTUREGodnnnmGm266icGDB9O0aVPuvffeWhteUZN7772XrKwsJk6cSFBQELfccgsjRow44fd0XWExAtSpVlBQwN69e6sc+81vfkOnTp2499576dat2wmfGTduHMXFxXz22WfeY4MHD6ZHjx6nPaA4Pz8fh8NBXl4e0dHR5/YljlNaVk7oNHMhpaIp24lokuCza4uIyDGlpaXs3r2bNm3a1GrLv5ycx+Ohc+fOXHvttTzyyCM+u25Nf7dn8vs7YC03UVFRJwSYiIgI4uLivMcnTpxIixYtvGNypkyZwrBhw/jXv/7FqFGjmDVrFmvWrOHVV1/1e/1/Ljg4GJdhxWbx4CwvDXR1REREfGbv3r188803DBs2jLKyMqZPn87u3bu57rrrAl21atWJdW5OJj09vcoKiYMHD2bmzJm8+uqr9OzZkw8//JCPP/642lYefwuyWnBWZEWXwo2IiDQgVquVGTNm0L9/f4YMGcKmTZuYP38+nTt3DnTVqlWn5s0tWrSoxvcA11xzDddcc41/KnSGnNgIoxyXUwOKRUSk4UhOTmbZsmWBrsZpq9MtN/WN02KuE+By1rz+gIiIiNQehRsfquyWcjvVLSUiIhIoCjc+5PKOuVG3lIiISKAo3PiQq6Jbyq0xNyIiIgGjcONDCjciIiKBp3DjQ26L2S3l0YBiERGpBRdeeCF33323933r1q159tlna/yMxWKpcYPp0+Wr6/iDwo0PuStabjzaW0pERH7miiuuYOTIkdWe++6777BYLGzcuPGMrrl69WpuueUWX1TP68EHH6RXr14nHM/MzOSyyy7z6b1qi8KND7msFd1SLrXciIhIVZMnT2bevHns27fvhHNvvvkm/fr1o0ePHmd0zfj4eMLDw31VxRolJSX5Za9GX1C48SFPRcuNdgUXEZGf++Uvf0l8fDwzZsyocrywsJDZs2czZswYxo8fT4sWLQgPD6d79+689957NV7z591S27dvZ+jQoYSGhtKlSxfmzZt3wmfuvfdeOnToQHh4OG3btuXvf/87TqcTgBkzZvDQQw+xYcMGLBYLFovFW9+fd0tt2rSJX/ziF4SFhREXF8ctt9xCYWGh9/yNN97ImDFjePrpp2nWrBlxcXHccccd3nvVpjq1QnF951a4EREJDMMAZ3Fg7h0cDhbLKYvZbDYmTpzIjBkzuO+++7BUfGb27Nm43W6uv/56Zs+ezb333kt0dDRffPEFN9xwA+3atWPAgAGnvL7H4+Gqq64iMTGRVatWkZeXV2V8TqWoqChmzJhB8+bN2bRpEzfffDNRUVH85S9/Ydy4cWzevJmvv/6a+fPnA+BwOE64RlFRESNGjGDQoEGsXr2anJwcfvvb33LnnXdWCW8LFy6kWbNmLFy4kB07djBu3Dh69erFzTfffMrvcy4UbnzIsFaGG3VLiYj4lbMYHmsemHv/7QCERJxW0ZtuuomnnnqKxYsXc+GFFwJml9SvfvUrWrVqxT333OMte9dddzF37lw++OCD0wo38+fP58cff2Tu3Lk0b24+i8cee+yEcTL333+/9+fWrVtzzz33MGvWLP7yl78QFhZGZGQkNpuNpKSkk95r5syZlJaW8vbbbxMRYX736dOnc8UVV/DEE0+QmJgIQJMmTZg+fTpBQUF06tSJUaNGsWDBgloPN+qW8iG3NQQAw137TW4iIlL/dOrUicGDB/PGG28AsGPHDr777jsmT56M2+3mkUceoXv37sTGxhIZGcncuXNJT08/rWtv27aN5ORkb7ABGDRo0Anl3n//fYYMGUJSUhKRkZHcf//9p32P4+/Vs2dPb7ABGDJkCB6Ph7S0NO+xrl27EhQU5H3frFkzcnJyzuheZ0MtNz50rOVG3VIiIn4VHG62oATq3mdg8uTJ3HXXXbz44ou8+eabtGvXjmHDhvHEE0/w3HPP8eyzz9K9e3ciIiK4++67KS/3XW/AihUrmDBhAg899BAjRozA4XAwa9Ys/vWvf/nsHscLDg6u8t5iseDxeGrlXsdTuPEhT1DFX6K6pURE/MtiOe2uoUC79tprmTJlCjNnzuTtt9/mtttuw2KxsGzZMkaPHs31118PmGNofvrpJ7p06XJa1+3cuTMZGRlkZmbSrFkzAFauXFmlzPLly2nVqhX33Xef99jevXurlAkJCcHtdp/yXjNmzKCoqMjberNs2TKsVisdO3Y8rfrWJnVL+ZBR0S2FW+FGRESqFxkZybhx45g6dSqZmZnceOONAKSmpjJv3jyWL1/Otm3b+N3vfkd2dvZpX3f48OF06NCBSZMmsWHDBr777rsqIabyHunp6cyaNYudO3fy/PPPM2fOnCplWrduze7du1m/fj2HDh2irOzE3ogJEyYQGhrKpEmT2Lx5MwsXLuSuu+7ihhtu8I63CSSFG1+qbLlRuBERkRpMnjyZo0ePMmLECO8Ymfvvv58+ffowYsQILrzwQpKSkhgzZsxpX9NqtTJnzhxKSkoYMGAAv/3tb3n00UerlLnyyiv5wx/+wJ133kmvXr1Yvnw5f//736uU+dWvfsXIkSO56KKLiI+Pr3Y6enh4OHPnzuXIkSP079+fq6++mosvvpjp06ef+cOoBRbDMIxAV8Kf8vPzcTgc5OXlER0d7dNrL33595yf9RZrEq+l322v+fTaIiJiKi0tZffu3bRp04bQ0NBAV0d8qKa/2zP5/a2WG1+yVXZLabaUiIhIoCjc+JARZIYbi0fhRkREJFAUbnzIUjHmxurRVHAREZFAUbjxIYtNLTciIiKBpnDjS0HmbqlWhRsRkVrXyObDNAq++jtVuPEhtdyIiNS+ylVvi4sDtFGm1JrK1ZiP37LhbGiFYh+yVLTcBCnciIjUmqCgIGJiYrx7FIWHh3t32Jb6y+PxcPDgQcLDw7HZzi2eKNz4kLXi/00o3IiI1K7KHav9sQmj+I/VaiUlJeWcw6rCjQ9ZbBVjbgyFGxGR2mSxWGjWrBkJCQk4nfo3t6EICQnBaj33ETMKNz4UVBFughRuRET8Iigo6JzHZ0jDowHFPmQNNsONTeFGREQkYBRufCgo2JwtZTNcAa6JiIhI46Vw40PWYHOTL3VLiYiIBI7CjQ8FVaxzE6xwIyIiEjAKNz5kC6kYc4O6pURERAJF4caHbBXdUsEKNyIiIgGjcONDNu9sKYUbERGRQFG48SGb3Qw3wRY3eDwBro2IiEjjpHDjQ5UtNwCGuyyANREREWm8FG58KCQkzPuz26lwIyIiEggKNz4UbA/x/lxernAjIiISCAo3PhRss+E0zD1OXGUKNyIiIoGgcONDNqsFZ8VepE5naYBrIyIi0jgp3PiQxWKhvCLcuNQtJSIiEhAKNz7mqgg3brXciIiIBITCjY85LWq5ERERCSSFGx9zEgyAS1PBRUREAkLhxsfcFjPceFzlAa6JiIhI46Rw42Mui8bciIiIBJLCjY95W26carkREREJBIUbH3NVhBu3S2NuREREAkHhxseOtdwo3IiIiASCwo2Pua1muDE0oFhERCQgFG58zKPZUiIiIgGlcONjHrXciIiIBFRAw81LL71Ejx49iI6OJjo6mkGDBvHVV1+dtPyMGTOwWCxVXqGhoX6s8akdCzcacyMiIhIItkDevGXLljz++OOkpqZiGAZvvfUWo0ePZt26dXTt2rXaz0RHR5OWluZ9b7FY/FXd0+INN2613IiIiARCQMPNFVdcUeX9o48+yksvvcTKlStPGm4sFgtJSUn+qN5ZMawh5g8KNyIiIgFRZ8bcuN1uZs2aRVFREYMGDTppucLCQlq1akVycjKjR49my5YtNV63rKyM/Pz8Kq/aZARVhhtnrd5HREREqhfwcLNp0yYiIyOx2+3ceuutzJkzhy5dulRbtmPHjrzxxht88skn/Pe//8Xj8TB48GD27dt30utPmzYNh8PhfSUnJ9fWVwHACDK7pdCYGxERkYCwGIZhBLIC5eXlpKenk5eXx4cffsjrr7/O4sWLTxpwjud0OuncuTPjx4/nkUceqbZMWVkZZWXHgkZ+fj7Jycnk5eURHR3ts+9R6buXp3BB1gzWJF1Lv1tf8/n1RUREGqP8/HwcDsdp/f4O6JgbgJCQENq3bw9A3759Wb16Nc899xyvvPLKKT8bHBxM79692bFjx0nL2O127Ha7z+p7KobN7JayaMyNiIhIQAS8W+rnPB5PlZaWmrjdbjZt2kSzZs1quVZnoGK2lFXhRkREJCAC2nIzdepULrvsMlJSUigoKGDmzJksWrSIuXPnAjBx4kRatGjBtGnTAHj44YcZOHAg7du3Jzc3l6eeeoq9e/fy29/+NpBfo6rKlhuPBhSLiIgEQkDDTU5ODhMnTiQzMxOHw0GPHj2YO3cul1xyCQDp6elYrccal44ePcrNN99MVlYWTZo0oW/fvixfvvy0xuf4i8VmdoEp3IiIiARGQMPNf/7znxrPL1q0qMr7f//73/z73/+uxRr5QMVUcKvCjYiISEDUuTE39Z3VG2405kZERCQQFG58zGJTy42IiEggKdz4WOWYmyBD4UZERCQQFG58zBqslhsREZFAUrjxMWtFy41NLTciIiIBoXDjY0HB6pYSEREJJIUbH6vslgoyXAGuiYiISOOkcONjld1SwWq5ERERCQiFGx+zhVSOuVHLjYiISCAo3PiYLTjU/BO13IiIiASCwo2PVQ4oDkYtNyIiIoGgcONjtooBxcFquREREQkIhRsfs1VOBccAjzvAtREREWl8FG58LMQeduyNW5tnioiI+JvCjY9VzpYCcDtLA1gTERGRxknhxseCjws3zvKyANZERESkcVK48bFgm5UywwYo3IiIiASCwo2PBVutODHDjatc3VIiIiL+pnDjY1ar5bhwo5YbERERf1O4qQUuhRsREZGAUbipBeWWYABcToUbERERf1O4qQWVLTdul8KNiIiIvync1AK3pSLcaJ0bERERv1O4qQWuim4pj1MrFIuIiPibwk0tcGnMjYiISMAo3NQCd2XLjcbciIiI+J3CTS2oHHNjqFtKRETE7xRuaoHbGgKo5UZERCQQFG5qgcfbLaWWGxEREX9TuKkFHqsZbgy13IiIiPidwk0tOBZunAGuiYiISOOjcFMLPBVjbnCrW0pERMTfFG5qQWXLjcKNiIiI/ync1ALDG2405kZERMTfFG5qgRFkdksZmi0lIiLidwo3taEi3Fg8GlAsIiLibwo3tSHI7JayaMyNiIiI3ync1IbKlhu3Wm5ERET8TeGmFhjebim13IiIiPibwk0tsNg05kZERCRQFG5qQWW4sWrMjYiIiN8p3NQCS0W3lNVQy42IiIi/KdzUAovNDoBV3VIiIiJ+p3BTCyq7pYLUciMiIuJ3Cje1wFoZbtRyIyIi4ncKN7UgKDjU/FMtNyIiIn6ncFMLvC03hivANREREWl8FG5qgTXYHFBsU8uNiIiI3ync1IKgYLPlRuFGRETE/xRuaoEtxBxzY1O3lIiIiN8p3NSCoIp1bmwo3IiIiPibwk0tCKoYcxOMuqVERET8LaDh5qWXXqJHjx5ER0cTHR3NoEGD+Oqrr2r8zOzZs+nUqROhoaF0796dL7/80k+1PX2V3VLBuMAwAlwbERGRxiWg4aZly5Y8/vjjrF27ljVr1vCLX/yC0aNHs2XLlmrLL1++nPHjxzN58mTWrVvHmDFjGDNmDJs3b/ZzzWtmq2i5sWKAxx3g2oiIiDQuFsOoW00LsbGxPPXUU0yePPmEc+PGjaOoqIjPP//ce2zgwIH06tWLl19+udrrlZWVUVZW5n2fn59PcnIyeXl5REdH+/4LANmHDpM4va355m8HICSiVu4jIiLSWOTn5+NwOE7r93edGXPjdruZNWsWRUVFDBo0qNoyK1asYPjw4VWOjRgxghUrVpz0utOmTcPhcHhfycnJPq13dSpbbgA8zvJav5+IiIgcE/Bws2nTJiIjI7Hb7dx6663MmTOHLl26VFs2KyuLxMTEKscSExPJyso66fWnTp1KXl6e95WRkeHT+lcnOCQEj2EBwOksrfX7iYiIyDG2QFegY8eOrF+/nry8PD788EMmTZrE4sWLTxpwzpTdbsdut5+6oA+F2IJwYsOOE5ezHP/eXUREpHELeLgJCQmhffv2APTt25fVq1fz3HPP8corr5xQNikpiezs7CrHsrOzSUpK8ktdT1dwkJXiynBTVhLo6oiIiDQqAe+W+jmPx1NlAPDxBg0axIIFC6ocmzdv3knH6ARKkNWCkyAAnM7qv4uIiIjUjoC23EydOpXLLruMlJQUCgoKmDlzJosWLWLu3LkATJw4kRYtWjBt2jQApkyZwrBhw/jXv/7FqFGjmDVrFmvWrOHVV18N5NeolpNgAFzlCjciIiL+FNBwk5OTw8SJE8nMzMThcNCjRw/mzp3LJZdcAkB6ejpW67HGpcGDBzNz5kzuv/9+/va3v5GamsrHH39Mt27dAvUVTsppMR+tWy03IiIiflXn1rmpbWcyT/5c7HmwM605QPro/5HSe/ipPyAiIiInVS/XuWloXBazW0otNyIiIv6lcFNLXBXdUi6FGxEREb9SuKkl7orhTB6FGxEREb9SuKkl7opuKY9L4UZERMSfFG5qicsaAoDHpb2lRERE/EnhppZ4LJXdUgo3IiIi/qRwU0vcVrNbylC3lIiIiF8p3NQST0W3lKFuKREREb9SuKklnsqWG7fCjYiIiD8p3NSSynCDuqVERET8SuGmlhjelhtngGsiIiLSuCjc1BIjSGNuREREAkHhppYYFQOKLR6FGxEREX9SuKktQWa3lEUDikVERPxK4aaWVLbcoHAjIiLiVwo3tcVW0S2lAcUiIiJ+pXBTW4I05kZERCQQFG5qiaWi5cbqUcuNiIiIPync1BZvy43CjYiIiD+dVbjJyMhg37593vfff/89d999N6+++qrPKlbfqeVGREQkMM4q3Fx33XUsXLgQgKysLC655BK+//577rvvPh5++GGfVrC+stjsAARpzI2IiIhfnVW42bx5MwMGDADggw8+oFu3bixfvpx3332XGTNm+LJ+9ZZVLTciIiIBcVbhxul0YrebLRPz58/nyiuvBKBTp05kZmb6rnb1mLWy5cZQuBEREfGnswo3Xbt25eWXX+a7775j3rx5jBw5EoADBw4QFxfn0wrWV8fCjSvANREREWlczircPPHEE7zyyitceOGFjB8/np49ewLw6aeferurGjtrsLn9gs3QmBsRERF/sp3Nhy688EIOHTpEfn4+TZo08R6/5ZZbCA8P91nl6jNrsFpuREREAuGsWm5KSkooKyvzBpu9e/fy7LPPkpaWRkJCgk8rWF/ZgkPNPxVuRERE/Oqsws3o0aN5++23AcjNzeW8887jX//6F2PGjOGll17yaQXrq6CKlhubBhSLiIj41VmFmx9++IELLrgAgA8//JDExET27t3L22+/zfPPP+/TCtZXleEmGIUbERERfzqrcFNcXExUVBQA33zzDVdddRVWq5WBAweyd+9en1awvvK23KBuKREREX86q3DTvn17Pv74YzIyMpg7dy6XXnopADk5OURHR/u0gvVVcEW4CcEFhhHg2oiIiDQeZxVuHnjgAe655x5at27NgAEDGDRoEGC24vTu3dunFayvbBWLHALgVteUiIiIv5zVVPCrr76a888/n8zMTO8aNwAXX3wxY8eO9Vnl6rPKlhsA3OVQsR2DiIiI1K6zCjcASUlJJCUleXcHb9mypRbwO44tJMz7s+EuxxLAuoiIiDQmZ9Ut5fF4ePjhh3E4HLRq1YpWrVoRExPDI488gsfj8XUd66WQ4GDchhlpXM6yANdGRESk8Tirlpv77ruP//znPzz++OMMGTIEgKVLl/Lggw9SWlrKo48+6tNK1kfBNgtObAThxFVeSnCgKyQiItJInFW4eeutt3j99de9u4ED9OjRgxYtWnD77bcr3AAhQVaKCSYUJ86yUsJO/RERERHxgbPqljpy5AidOnU64XinTp04cuTIOVeqIQiyWiivyI5OdUuJiIj4zVmFm549ezJ9+vQTjk+fPp0ePXqcc6UaAovFgqsi3LgVbkRERPzmrLqlnnzySUaNGsX8+fO9a9ysWLGCjIwMvvzyS59WsD5zVoabcoUbERERfzmrlpthw4bx008/MXbsWHJzc8nNzeWqq65iy5YtvPPOO76uY73ltJjDiDVbSkRExH/Oep2b5s2bnzBweMOGDfznP//h1VdfPeeKNQRuiw0MhRsRERF/OquWGzk9rooJ4B6FGxEREb9RuKlFbktFw1jJ0cBWREREpBFRuKlFaTZzunzzDS+AsyTAtREREWkczmjMzVVXXVXj+dzc3HOpS4PzfsR4hpQtJqlgDyx+Eob/I9BVEhERafDOKNw4HI5Tnp84ceI5VaghcQZH8Xfnb3gt5BlY9hx0uwqSuge6WiIiIg3aGYWbN998s7bq0SDFR9r5xtOPTY4L6Z63CD65E367AILOepKaiIiInILG3NSim4e2BeC3B8fhtjsgcz2seimwlRIREWngFG5qUf/WsQzvnEi2x8F/o282D377KBzZHdiKiYiINGAKN7Xs3pEdsVrgHxm9yW82GFwl8N9fwdZPwDACXT0REZEGR+GmlqUmRnFN32TAwtTyyRjhTeHITvhgIrwyFH6aq5AjIiLiQwENN9OmTaN///5ERUWRkJDAmDFjSEtLq/EzM2bMwGKxVHmFhob6qcZn5w+XdCA02MoX+8NYdOnXMPQvEBIJWRth5rXw+nDY/D9wlQe6qiIiIvVeQMPN4sWLueOOO1i5ciXz5s3D6XRy6aWXUlRUVOPnoqOjyczM9L727t3rpxqfnSRHKDcNaQPAo98ewDVsKkzZCIN/D7Yw2L8GPrwJ/t0VFjwMuekBrrGIiEj9ZTGMutMncvDgQRISEli8eDFDhw6ttsyMGTO4++67T3vBwLKyMsrKju3tlJ+fT3JyMnl5eURHR/ui2qclv9TJ0CcXklvs5NGx3ZhwXivzREEWrHkD1s6AwmzzmMUKcakQlQiRFa+oZpDQ2VwnJzLBb/UWERGpC/Lz83E4HKf1+7tOLbiSl5cHQGxsbI3lCgsLadWqFR6Phz59+vDYY4/RtWvXastOmzaNhx56yOd1PVPRocHceVF7/vnFNu7/eDPbswu5Z0RHIqOS4KK/wdA/w49fwJr/wO4lcCjNfFUnIgGSukGzntC8t/lyJIPF4t8vJSIiUgfVmZYbj8fDlVdeSW5uLkuXLj1puRUrVrB9+3Z69OhBXl4eTz/9NEuWLGHLli20bNnyhPJ1peUGoNzlYepHm/jfD/sAaOYI5eHR3bikS2LVgrnpcGQXFOaYrTmF2XB0L2RvMY9TzV9ZeJwZclIGQevzoXkfsIXU/pcSERHxgzNpuakz4ea2227jq6++YunSpdWGlJNxOp107tyZ8ePH88gjj5yy/Jk8nNry3faD3DdnM+lHigG4tEsiv72gLf1aNcFqPUXrS3kRZG+F7E2QuQEOrDNDj8dVtZwtDJL7Q+oI6DEOIuNr6duIiIjUvnoXbu68804++eQTlixZQps2bc7489dccw02m4333nvvlGXrQrgBKCl38/y323l1yS7cHvOvIDk2jLG9W3JV7xa0bhpx+hdzlkLOFti3BvYshb3LoPjwsfNWG3QYCb1vgPbDtf2DiIjUO/Um3BiGwV133cWcOXNYtGgRqampZ3wNt9tN165dufzyy3nmmWdOWb6uhJtKP2bl88bS3Xy5KYvCsmOtL23jI+jW3EG3FtF0a+6ga3MHjvDg07uoYcDBNNi9GDbMggM/HDsXmQQXTTWDjjXIx99GRESkdtSbcHP77bczc+ZMPvnkEzp27Og97nA4CAsLA2DixIm0aNGCadOmAfDwww8zcOBA2rdvT25uLk899RQff/wxa9eupUuXLqe8Z10LN5VKyt18szWLj37Yz3fbD+L52d+KxQLdmju4ILUpQzvE0yelCSG205zJn70V1r9rBp3iQ+axpB5w2ZPQapBvv4iIiEgtqDfhxnKS2T1vvvkmN954IwAXXnghrVu3ZsaMGQD84Q9/4KOPPiIrK4smTZrQt29f/vnPf9K7d+/TumddDTfHO1JUzsZ9uWw5kM+WA3ls3p/vHZ9TKTwkiMHtmvKLTgn8olMCSY7TWMjQVW7Oxlo4DcrMmWl0uxqGPwgxyb7/IiIiIj5Sb8JNINSHcFOdnPxSlu44xJKfDrJ0xyEOFVZdzbhLs2iGd05gbJ+WtDnVeJ2iQ+ZigT+8DRhgCYLOv4QBv4NWgzWlXERE6hyFmxrU13BzPI/HYGtmPovScljwYw7rM3KrbE81oE0s4/olc3n3ZoSF1DCu5sB6mPeAOTanUkJXGHAz9JqgqeQiIlJnKNzUoCGEm587XFjGorSDfL7xAIt/OjZeJ8puY3Tv5owfkELX5o6TXyB7C3z/Gmx8H5wV3V9NO8Kop6FN9StFi4iI+JPCTQ0aYrg5XmZeCf9bu4/312SQcaTEe7xnSwfjB6RwRc/mRNhPMhW8JNcceLz031B00DzW7WoY8ShEJdV+5UVERE5C4aYGDT3cVPJ4DFbuOszM79OZuyULp9v8a46027jtwnZMPr8NocEn6bIqyYVv/2kOPjY8EBIFI/4JfW/0W/1FRESOp3BTg8YSbo53uLCM//2wj/e+z2D3IXPH9eTYMO67vAsjuiaedNYaB9bDF3+E/WvN98MfgvPv9kudRUREjqdwU4PGGG4qeTwGn244wLSvtpGdb+63NbhdHA9c0YVOSSd5Fh4PLJoGS5403w9/EM7/g38qLCIiUkHhpgaNOdxUKipz8fLinbyyZBflLg9BVgs3DGzFHy7pgCPsJKsgL3oCFj1m/nzxP+CCP/qvwiIi0ugp3NRA4eaYjCPFPPblNr7anAVA08gQ7h3ZiV/1aVn9Bp6Ln4SFj5o/X/wAXPAnP9ZWREQaM4WbGijcnOi77Qd58NMt7DxojsfpnRLDs+N60SqumsUAlzxlDjYGOP+P8Iu/g/U0t4EQERE5S2fy+1u/lYQLUuP5aspQ/nZ5JyJCgliXnsuYF5exZs+REwsP/bPZLQWw9BmYcwu4yvxbYRERkRoo3AgAITYrtwxtx/w/DaN7CwdHi51c99oqPlm//8TCF/wRRv8fWG2waTb891fm9HEREZE6QOFGqmjmCOP93w3k0i6JlLs9TJm1nucXbOeE3sveE+C6D8w1cPZ8B2+MgNyMwFRaRETkOAo3coLwEBsvXd+Xmy9oA8Az837i3v9txOP5WcBpfzHc9BVENYODP8KrF8L2+f6vsIiIyHEUbqRaQVYL943qwj/HdCPIauGDNft44NPNJ7bgJHWH386HxO5QfAje/RV8cz+4yqu/sIiISC1TuJEaXT+wFc9c2xOLBf67Mp0n56adWMjR0gw4/W823y9/weymOrLLv5UVERFB4UZOw+heLXh0THcAXlq0kxcX7jixUHCouYv4uHchNAYO/AAvD4U9y/xbWRERafQUbuS0XHdeClMv6wTAU3PTeHvFnuoLdv4l3LYMUgZBeQF8MFEDjUVExK8UbuS0/W5YO+68qD0AD3yyhQ/X7qu+oKMlXP8RJPUwx+G8fz04S/xYUxERacwUbuSM/OnSDtw4uDUAf/lwA59uOFB9wZBwGPdfCIuFzPXw+R+hcS2GLSIiAaJwI2fEYrHwwC+7MH5AMh4D/vD+er7alFl94Sat4Jo3wWKFDTNh9ev+rayIiDRKCjdyxqxWC4+O6c5VfVrg9hjc9d465m/Nrr5w2wvhkkfMn7/+K+xd7rd6iohI46RwI2fFarXw1NU9uaJnc1weg9vf/YHFPx2svvCgO6Db1eBxwfs3wNE9fq2riIg0Lgo3ctaCrBaeubYnI7smUe72cPPba1j4Y86JBS0WuPKFYwOM370GSo76v8IiItIoKNzIOQkOsvL8+N5c0iWRcpeHW95Zw9wtWScWDAk396KKbgGHfjJbcLSKsYiI1AKFGzlnITYr/zehD6O6N8PpNruoPqtuFlV0s6qbbX56l2ZQiYiIzynciE8EB1l57te9uKq3Och4yqx1/K+6dXCSusG1b4ElCDbOgsVP+L+yIiLSoCnciM/Ygqw8dU1Pft3fnCZ+z4cbqp8m3v5i+OUz5s+LpsEXf4KiQ/6trIiINFgKN+JTQVYLj43tzoTzUjAM+Mv/NrLvaPGJBfveCEP/bP68+nV4vjcsfRacpf6sroiINEAKN+JzVquFB6/sSq/kGApKXfzh/fW4PdWMrfnF/TDpM2jWE8ryYf4/YHp/2PaZ/ystIiINhsKN1IrgICvP/7o3kXYbq/ccrX4ncYA2Q+HmRTDmZYhqDnnp5l5UC6dpsLGIiJwVhRupNSlx4TwypisAzy3Yztq9R6ovaLVCr/Fw11oYdKd5bPHjMOdWcJX5qbYiItJQKNxIrRrbuyVjejWvmEG1nvxS58kLh4TDiEfhiueOzaZ65yooPkkoEhERqYbCjdS6h8d0Izk2jH1HS5j60SaMU3U39b0Rrv8Q7NGwdyn85xLY/BGUFfqlviIiUr8p3Eitiw4N5rlf9ybIauGLjZk8O3/7qT/U7hdw01xwJMPhHfDhb+CpdvDedbBhFpTm1X7FRUSkXlK4Eb/ok9KER0Z3A8zxN7PXZJz6Q4ld4OZvYcgUaNIGXKWQ9gXM+R081wvSvqrdSouISL1kMU7ZR9Cw5Ofn43A4yMvLIzo6OtDVaXSe+PpHXlq0E5vVwozfDOD81Kan90HDgOwtsO1T2DQbjuwyj/e/GS59BILDaq/SIiIScGfy+1stN+JXf760I1f2bI7LY3Dbf9fyY1b+6X3QYjG3brjob3D7ymOzqla/Bq/9ArK31l6lRUSkXlG4Eb+yWi08dU0PBrSJpaDMxW/eXM2B3JIzu4jNbs6quv5/EJEAOVvh1Qth+XTwuGul3iIiUn8o3Ijf2W1BvHpDX9rGR5CZV8o1L69gR85ZzIRqPxxuWw6pl4K7DL65D94YCYdOY8CyiIg0WAo3EhAx4SG8M/k82jaNYH9uCde8vJz1GblnfqHIeLjuA3NtnJAo2Pc9vHw+LHterTgiIo2Uwo0ETIuYMGbfOoieLR0cLXZy3WsrWfLTwTO/kMViro1z+wpzCrmrFOb9HV6/GPYu93m9RUSkblO4kYCKi7Qz8+aBXJDalOJyN5PfWs0n6/ef3cVikuH6j+DKF8wFAA+sgzcvg1kT4NBJ9rYSEZEGR+FGAi7CbuM/k/rzyx7NcLrNbRoe/WIrTrfnzC9msUCfiXDnGrM1x2KFHz+H/zsPvrgHig77vP4iIlK3aJ0bqTM8HoMn5v7IK4vNNWwGtI5l+nW9SYgOPfuL5myDef+A7XPN96EOGPZXGHAzBAX7oNYiIuIPZ/L7W+FG6pyvN2dyz+yNFJa5iI+yM318b85rG3duF921GObeB9mbzPdxqTByGqRecu4VFhGRWqdwUwOFm/ph18FCbvvvD6RlFxBktfC3yztz05DWWCyWs7+oxw3r3oEFj0DxIfNYq/Oh+9XQ+QqIOM3VkkVExO8UbmqgcFN/FJe7+NtHm/h4/QEArurTgsfGdic0OOjcLlyaB4ufhFWvgMdpHrMEQevzoesY6HoVhMWc2z1ERMSnFG5qoHBTvxiGwZvL9vDol9twewx6tHTwyg19aebwwV5SR/fC5v/B1o8hc8Ox48ER0HMcDPgdJHQ69/uIiMg5U7ipgcJN/bRsxyHumPkDucVOmkbaefn6PvRrHeu7GxzZDVs/gQ2z4OC2Y8fbDIN+v4H2l4A90nf3ExGRM6JwUwOFm/or40gxN7+9hh+zCggOsvDY2O5c0y/ZtzcxDNjzndlllfYlGBXT0YPs0HYYdLwMOlwG0c18e18REamRwk0NFG7qt+JyF/fM3sCXm7IA+N2wtvxlRCeCrOcw0PhkctNhzRuwZQ4c3VP1XPJ50HUsdBkN0c19f28REaniTH5/B3QRv2nTptG/f3+ioqJISEhgzJgxpKWlnfJzs2fPplOnToSGhtK9e3e+/PJLP9RW6oLwEBvTx/fh9xenAvDK4l387p21FJW5fH+zmBQY/iD8fj3cvhIufgBa9jfPZayCr/8Kz3SG/4ww97LKWA2uMt/XQ0REzkhAW25GjhzJr3/9a/r374/L5eJvf/sbmzdvZuvWrURERFT7meXLlzN06FCmTZvGL3/5S2bOnMkTTzzBDz/8QLdu3U55T7XcNByfrN/Pnz/cSLnLQ6ekKKZf14f2CX4YF5N/ALZ+ag5ETl9R9VyQHVr0MVt2uoyG5r3NVZNFROSc1NtuqYMHD5KQkMDixYsZOnRotWXGjRtHUVERn3/+uffYwIED6dWrFy+//PIp76Fw07CsSz/KzW+v5VBhGUFWCzcMbMWUi1NpEhHinwrk7Ydtn8LuJZC+EkqOVD2f0AV6Xw89xmkdHRGRc1BvuqV+Li8vD4DY2JPPglmxYgXDhw+vcmzEiBGsWLGi2vJlZWXk5+dXeUnD0TulCZ/eOYRLuiTi9hjMWL6HC59exJvLdp/d3lRnytECBt4G49+Dv+yCO9fC6Beh26/MVpycrTD3b/CvjvC/30JBVu3XSUSkkasz4cbj8XD33XczZMiQGruXsrKySExMrHIsMTGRrKzqf2lMmzYNh8PhfSUn+3h2jQRc85gwXpvYj3d/ex6dkqLIK3Hy0Gdbufy579hyIM9/FbFYoGl7s6Xm6jfgnjQY9S9o3gc8Ltg0G148z5xuXncaTEVEGpw6E27uuOMONm/ezKxZs3x63alTp5KXl+d9ZWRk+PT6UncMad+UL35/AdOu6k5cRAjbcwoZ8+IyXl2yE48nAGEirAn0/y3cshBuWQzNekFpLsz5HcwcZ47dERERn6sT4ebOO+/k888/Z+HChbRs2bLGsklJSWRnZ1c5lp2dTVJSUrXl7XY70dHRVV7ScAVZLYwfkMK8Pw7j0i6JON0Gj335I9f/ZxWZeSWBq1jzXvDbBeaMq6AQc5fyFweaXVVLnoJtn8GhHeCuhVlfIiKNTEAHFBuGwV133cWcOXNYtGgRqampp/zMuHHjKC4u5rPPPvMeGzx4MD169NCAYqnCMAzeX53BQ59tpcTpxhEWzCNjunFFj2bntgHnucrZBp/cAfvXnngu1GHOsup2tbnXlfUc99ESEWkg6s1sqdtvv52ZM2fyySef0LFjR+9xh8NBWJi5d9DEiRNp0aIF06ZNA8yp4MOGDePxxx9n1KhRzJo1i8cee0xTweWkdh0s5O7317Nxnzn+ZmTXJP45thtNI+2Bq5TbBTu/hezNcDANDv4Ih34CZ/GxMpFJ0O0q6DMREjoHrq4iInVAvQk3J/t/z2+++SY33ngjABdeeCGtW7dmxowZ3vOzZ8/m/vvvZ8+ePaSmpvLkk09y+eWXn9Y9FW4aJ6fbw4sLdzD92x24PAaxESE8PLorv+xRh1YX9rhh73Jz4PHWT8zxOZXaXgjn3Qapl4K1TvQmi4j4Vb0JN4GgcNO4bTmQxz2zN7It01wSYFT3ZvxzTDf/rYtzulzlsHMBrPtv1T2uYttB/8nQ9SrtbyUijYrCTQ0UbqTcZbbivLjQbMVJiLLz5NU9uLBjQqCrVr2je2H1a/DD21BaObXdAimDKva3uhKiqh9QLyLSUCjc1EDhRipt3p/H3e+vZ0dOIQA3DGzF1Ms7ER5iC3DNTqKsEDbOgo0fmHtbeVkgeYC5Y3nHy6FpB235ICINjsJNDRRu5HilTjdPfP0jby7bA0CbphE8NrY7g9rFBbZip5K3zxyXs2UO7Ftd9VxsO+h0OXS/FpK6K+iISIOgcFMDhRupztLth7hn9gay8ksBuLRLIn+7vDOtm1a/gWudkrcffvoK0r4y97hylx87F98Zeo6D7teYs6/cZeZ5VznYoyAkPHD1FhE5Awo3NVC4kZPJK3byr3lpvLsqHbfHIDjIwo2DW3PnL1JxhAUHunqnp6wAdiyALR9B2tdmmDkZWxj0vRGGTNHgZBGp8xRuaqBwI6eyPbuAf36xjcU/HQQgKtTGuH7JTBzUmpS4etTSUZJrdl1t/AD2Lj15uaAQcy2dIXdDjPZeE5G6SeGmBgo3croWpeXw6Bfb2F4x4NhigYs7JfKbIa0Z3C4usKscn6nSfDDcZpAJCgGrzVxEcMlTkL7CLGMNhpb9oVkPaNbTfDXtAEH1pNVKRBo0hZsaKNzImfB4DBZvP8iMZXu8LTkAg9rG8ejYbrSNjwxg7XzAMGDPUlj8BOz57sTzQSHmAOX4DtC0I8R3hMSuEJcKQXV0VpmINEgKNzVQuJGztfNgIW8v38Os1RmUuTyEBFm546L23HphW+y2BrAH1ME02P8DZG2EzA2QtQnK8qsvG2Q3t4RI6g4t+5n7YYU18W99RaRRUbipgcKNnKv0w8Xc/8lmllS05LSLN6ePn9e2jk8fP1MeD+Tvq9j7Kg0OVfyZvQXKC6uWDbJD519CrwnmVhHHb/jpNGegERzqt6qLSMOjcFMDhRvxBcMw+GxjJg9/tpVDheaMpGv7tWTqZZ3r3lYOvubxQO4es2UncyP89LW5AWil6BYQHgvFR6HkiLkZaFAIdBplhp92v9Bu5yJyxhRuaqBwI76UV+zk8a9/5L3v0wGIjQjh/lGdGdu7Rf0acHwuDMPsxlr3X3PTz+M3/KxOVDNz3Z2QSMhNh9y95hYTViv0mQT9boKwGH/UXETqEYWbGijcSG1Ys+cIf5uziZ+yze6aIe3juG1Ye85rG0twUCPaxdtZag5QBghvAmGxZivO0T2wfqY5Lb3kSM3XCImCfjfCwNshug7t2i4iAaVwUwOFG6kt5S4Pry/dxXPzt1PmMnfxdoQFM7xzIiO7JXFBalNCgxt5d4yr3OzG2vYZ2OwQ0wqatIKYFDiyC5Y9Dwe3mWWtweZ09CatK8q0AkcLsEebrT72SHOV5dAYbTEh0ggo3NRA4UZqW/rhYl5avJN5W7M4VHhsK4SmkSE8OrY7I7pqB++TMgzYPg+WPVfzwoPHi2tvdnN1vwbi2lW91tHdkPMjJHUzA5SI1FsKNzVQuBF/cXsM1uw5wtdbsvhqU5Z336qr+rTgH1d0rT9bOgRK5Syto3vMV+5eyM+E8gJzh/Tywqr7aAG06AfJ50HOVjiw7tj4n6AQc5uJ8/+o/bRE6imFmxoo3EgglLnc/Hvedl5dshOPAc0coTx5dQ8uSI0PdNXqt9J8SPvSHMuzayEYnqrng0LM2VtHd5vvHclw6T/NdXmO78oyDHVtidRxCjc1ULiRQFq79wh/+mADew4XA3Bhx3iuG5DCLzolYGtMA49rQ2EObP4IDu8wV1Fu3hsSupjbR/z4OXw9FfIyzLJJ3c3gU3IUio9AaR5EJR3bdqJZL4htY4an4sPmIOiSo+ZMr+QBZkhSGBLxK4WbGijcSKAVl7t44qsfeWvFXu+xxGg74/olM25ACi1iwgJYuwasvBiW/tscz1PTbumnI6pZxT5cPSEkwgxQQSHmIOjSPCjMgoJs809XOaScZy5u2HJA9YsZquVI5JQUbmqgcCN1xa6Dhby/OoPZa/dxpMgcO2KxwLAO8YyvaM1pVNPI/eXoXkhfac60CmtivkKjzTV3Mjcce+XtM9fbCY8zp7SHOswZXVkbweM6u3vbwiBloHmtwhwozDb/NNzQ41oY/Puqg6IreTzmYoj2er6Xmcg5ULipgcKN1DVlLjffbMlm5qp0Vuw67D2eEGXnmn4t+XX/FJJjNQi2zigvNgcr7/seDv5ktgK5nRWvcjOARCZBVKL5p+ExNyXdtdhsyamRBTpfAeffbU5x373Y/Nye78zusdYXmAsddr5C21lIo6NwUwOFG6nLdh8qYtbqdD5cs4/Dx7XmXNQxgRsGtmJoh3iCrOq+qJcMw5z9tec7M/BEJkBkIkQkQEEmrJhurgF0OsKaQM/x0GGEuf5PdAuwHbfth7MU8vebr+AIczd3tfpIPadwUwOFG6kPyl0e5m/L5t1Ve1m241hrTssmYdwwsBUTBrYi0m4LYA2lVmRvheUvwKYPAIs5eLnNMGgz1BzwvPF9+OEdc0PTKizmas7hseZYn6KcE68d08rcyT22nZmY3eXHWpwiE8wB2C36mEFJ43+kDlK4qYHCjdQ3uw4W8u6qdGavySC/1BzrERMezG/Pb8PEwa2JDtV6OQ1OWQFYgqpfk8fjhh0LYP275no+uengKj2xXHC4GVTK8s2xPacrIsGcTRYRb44NCo02/3SWQsEBKMiC/ANmHVv0hXYXmYOlK7fKcJaaO8dnroO8/dDpl9Cy74n3MQzze+xZYn6+7UUKVVIjhZsaKNxIfVVS7uazDQd4efFOdh0qAiA61MZN57dh0qDWDX83cqmeYUDRQTPkFB82W3gcyWbXVWVYKDpsbmuRs81cDNESZM7wsgabO7Tn7jXHEWVvNQc3n434TuaMsZytJw64bjPUXECx7YVmfdO+gCVPQ+b6Y2Wa9YLz/2COJ9Ku8VINhZsaKNxIfef2GHy+8QDPL9jOzoNmyAmxWfll92ZMGJhCn5QmjWdHcvEtZwlkbTYDSmmuuc5PaZ75soVAVHMzPEU3N8PR3uWwc6EZjDjuV0l4nNnNFRJprjFUGXaa9QJX2bH9w4LDod0vYOe35mwwMLvNul1lthaFRJgbqQaHmUHN8Bx7WW3HzodEHGvl8rjNAGV4zIAXqYUyGwqFmxoo3EhD4fYYfLU5k5cW7WTLgXzv8U5JUVw/sBVX922pjTrFP4qPwN5lZqho3hscLY+1GuVmwIoX4Ye3jgUYezQMuMXc+T0izmxZ+v5VWPXysS0zfCWqGST1MNckSuwCbldFcMs1Q1t5MXicZihyO83PtOgD7S6GpqlVu8qcpbB/rbkcQEikGfQiE817hMeBVUs31CaFmxoo3EhDYxgGG/blMXPVXj7dcIBSp7kFQXyUnZsvaMOE81oRocHHEmhFh81xQlYb9LrOXEPo58oKYcN7ZstRedGxPcScxYAFLNZjL4+z4nyBWba82AwilqCKMhYzvHAOv+IcKdD+F+a0/PQVZgvVz/czq2S1meOVKpcAiEwwu9d+3tpkjzLDnT3aHM8UmWiGwegW5ow2twtytkDG9+Yra5P5mZhks7vR0dJcPTu+s9mCdjattAXZkL3JDJ6uMnCVmH+6nWbXYevz6+T4J4WbGijcSEOWV+Lkf2v38Z+lu9mfWwKYg49/M7gNw7sk0C4+Uq050niUF5ndbJkbIGuDuS5RcGjFQOmYiq6vSAiymcHDGmwOzt7zndnlVl2QiUw0N2h1l5uDqwuzoOgQ5xSiKoU6zHDjLDr98gldoGkHs5vQVWq2LrlKzZYomx1soeZ3tgTBkZ3mYO+igzVft9UQGHavOVaqMuQYhjk2a98aM2zFtjVn4FUuQeAqh4M/QvZm85lHN4PBd539s6iGwk0NFG6kMXC6PXy8bj//t2gnuw8d+4fSYoHkJuG0T4ikR0sH4wekkBitxeBETlBeBHuWHRsPlHyeubp0bNsTWzXczooVpyu23SjINAOEYZitN5UtSh6XOXutrODYeKaCTHNWWVnesevZo6FlxQ73zfuY98/LMFta8jLg8E5zD7WzHfxtsZpjm+LameOeKgNQeRFsmXMs1KUMMjeZ3f+D2e2Yv/9n1wkyW5SCI+DQT2ZrWqVmveB3i8+ufiehcFMDhRtpTNwegy83ZfLuqr38mFVAbrGzyvngIAtX9GjO5Ava0LW5I0C1FBHKCsyQA+ZYn1PNGHOVwaHt5gy4w9vNIBUcam7xYbObn3eVm604rjJzJW1HMiR1M7u0qltmAMw6LHsW1r514h5sVps5dslVbrYCVY6hqhTqgMTu5j2a94Ge487qUZyMwk0NFG6ksTIMg8NF5ezIKWR7dgGfbcjk+z1HvOcHtY1j0uDWXNxZe1qJNHr5B8wFJQ+mmesZtR5ibvxaGYoMw+yWO7LTbPFJ6GyGp1ocq6NwUwOFG5Fj1mfk8p+lu/lyUyZuj/lPQUKUnWv7JfPrAcm0bKI9rUSkblC4qYHCjciJ9ueW8M6Kvcxek1FlT6sBrWPp3CyadgmRtIuPoH1CJAlRGqMjIv6ncFMDhRuRkyt3efhmaxbvfZ9eZU+r47WICeO8NrEMbBvHeW1jSYkN16KBIlLrFG5qoHAjcnr2HCpi1e7D7DxYxI6cQnYeLCTjSDGen/2L0SImjIs6xXNx50QGtY3TVHMRqRUKNzVQuBE5e8XlLtbuPcqqXUdYueswG/bl4nQf+yckPCSI89s3ZVSPZozomqSgIyI+o3BTA4UbEd8pKXezYtch5m/LYcG2bLLzj00djQq1cWXP5lzdtyW9kmPUdSUi50ThpgYKNyK1wzAMthzI5+vNWcxZt9+7QjJA26YRXNw5gYs6JtCvdSwhNk01F5Ezo3BTA4Ubkdrn8Ris3HWY2Wv38dXmTO9+VwARIUGcn9qUizslclGnBOKj7AGsqYjUFwo3NVC4EfGvglInS346xLc/5rD4pxwOFR7br8digd7JMQzvksjQ1HhaxIQREx6sLiwROYHCTQ0UbkQCx+Mx2Hwgj29/zGHBthw27c87oYzdZiXJEUpidCg9WjgY2iGeAW1iNThZpJFTuKmBwo1I3ZGZV8KCbTnM35bNxn15HCmqZhdmzMAzoE0sg9s1pVOzKDokRtHcEaoWHpFGROGmBgo3InVXmctNTn4ZmXml7DtazMpdh1ny0yGy8ktPKBtpt9E+IZKLOyVw3XkpxEVq7I5IQ6ZwUwOFG5H6xTAMduQUsving6xLz+Wn7AJ2HyrCddxqgnablbG9W/CbIW3omBQFmF1gh4vKOVhQRkpcOJF2W6C+goj4gMJNDRRuROq/cpeHvYeLWJ+Ry39X7mXDvmNjdzolRVFQ6iKnoNS7wGBESBC/6tuSiYNa0T4hKlDVFpFzoHBTA4UbkYbFMAzW7j3KG8t28/XmrCrbQ1gsZvdVQanLe2xI+zgmnNeKwe3iiAkPCUCNReRsKNzUQOFGpOHad7SYLQfyiY+ykxQdSnyUHZvVwvKdh3lr+R7mb8uuEn7aJ0TSr1UT+rZqQo+WMbRpGqEFBkXqKIWbGijciDRe+44W89+V6XyzJYtdh4pOOG+zWmjTNIIOSVGkJkTSIiaMFk3CaBETRpIjFLtN09FFAkXhpgYKNyICcLiwjLV7j7J271F+SD/Kj5kFFJS5TlreYoEuzaIZ2TWJkd2SaJ8QqanoIn6kcFMDhRsRqY5hGGTmlZKWXcD27AJ25hRxIK+E/bklHMgtqbKFBJj7ZQ3tEE90WDB2m5XgIAshQVbaJUTSv7UWHRTxtTP5/a25kSIigMVioXlMGM1jwrioY0KVc4ZhcLCgjEVpB/l6SxZLtx9i16Giaru24Niig0NT4xncPo528ZEKOyJ+FNCWmyVLlvDUU0+xdu1aMjMzmTNnDmPGjDlp+UWLFnHRRRedcDwzM5OkpKTTuqdabkTkXBWUOlmYdpCNGbmUuTw43R7KXR6Ky92sz8g9YdFBqwVaNgmnXXwE7eIj6Zkcw9DUeBzhwQH6BiL1T71puSkqKqJnz57cdNNNXHXVVaf9ubS0tCpfLCEhoYbSIiK+FRUazJU9m3Nlz+YnnDt+0cHvth/ih71HKShzkX6kmPQjxSxMOwiYgadPShMu6pTAwLaxRNhtBFksWK0WbFYLMeEhRIfaNK5H5CwENNxcdtllXHbZZWf8uYSEBGJiYnxfIRGRc2SxWEhNjCI1MYrfXtDW7NIqLGNnThG7DhWyPbuQZTsOsT2nkDV7j7Jm79GTXivSbqNFTBjNY0JJcpg7pjvCgokONf/skBipgc0i1aiXY2569epFWVkZ3bp148EHH2TIkCEnLVtWVkZZWZn3fX5+vj+qKCICmGEnISqUhKhQBrWL8x7fd7SYxT8dZOGPB9m8Pw+Xx4PbY+D2GLg8BsXlbgrLXKRlF5CWXXDS6yfHhnFxp0Qu7pzAeW3itE6PCHVotpTFYjnlmJu0tDQWLVpEv379KCsr4/XXX+edd95h1apV9OnTp9rPPPjggzz00EMnHNeYGxGpy0rK3ezPPTZbKyuvlLwSJ/mlTvJLXBwtLmfT/jzKXcdmcQUHWbDbgrBawBZkxWqx0DQyhLbxEbRtGknbijE/7RIitdeW1Dv1cir46YSb6gwbNoyUlBTeeeedas9X13KTnJyscCMi9V5RmYtlOw6xYFsOC37M4VBh2ak/VKFFTBjtEyJJTYikVdMIkqJDaeYIJckRSmx4CFarurqkbqk3A4p9YcCAASxduvSk5+12O3a73Y81EhHxjwi7jUu7JnFp1yQ8HoMDeSW43Ga3lscwcLkNsvNL2XmwkF2HitiZU8jOg0UcKizztgot/ungCde126x0a+GgT0oMfVKa0KdVExKjQwPwDUXOTr0PN+vXr6dZs2aBroaISEBZrRZaNgk/4XiX5tFc1KnqjNKjReXsOGgObt6eU8C+oyVk55eSmVfKocIyylwe7+rNsBuAmPBgmjnCaF7RutM8JoyWTcJIiQ0nOTacuAhzE9LcYqe3Ky23xEnfVk1oFx9Z699f5HgBDTeFhYXs2LHD+3737t2sX7+e2NhYUlJSmDp1Kvv37+ftt98G4Nlnn6VNmzZ07dqV0tJSXn/9db799lu++eabQH0FEZF6p0lECP0jYunfOvaEc063h/QjxaxLz2Vd+lF+SM8lLSuf3GInucVOtmVWPykjPCQIw4ASp/uEc22aRvCLTglc3CmBPq2aaEFDqXUBDTdr1qypsijfH//4RwAmTZrEjBkzyMzMJD093Xu+vLycP/3pT+zfv5/w8HB69OjB/Pnzq13YT0REzlxwkNUcdBwfydV9WwLm2J6Mo8Vk5pqtO1l5JezPLSXjaDEZR4rJyi+luPxYqGkaaadFTCj24CDWpR9l96Ei/rN0N/9ZarYCRdptxEaEEBcZQlyEnZZNwkiODa9oBQqjdVyEApCckzozoNhftEKxiIhvlbnc7D9aAkDzmLAqwaSwzMXS7QeZvy2HhT/mcLio/JTXs1qgXXwkXZpH07V5NF2aOWgbbw561kDnxqtezpbyF4UbEZHAMAyD/FIXR4rKOVxYxuGicg4WlLHvaAkZR4rJOFrM3sPF5JU4q/283WalVVw4reIiSIy2E2G3ERFiIzwkiPAQG063h1KnmzKX+acjLJg+rZrQvYVDLUENQKOaLSUiIvWDxWLBEWaurtymacRJy+Xkl7LlQD5bM/PZciCPbZkFZBwppszl4afsQn7KLjyj+wYHWejSLJo+rZpwXps4BraNJSY85Fy/jtRharkREZE6z+X2cCC3lD2Hi9hzuIhDheUUl7koKndRVOamxOkmJMiK3WbFHhyE3WYlK6+UtelHOVhQdf0fiwW6No9mcLumpMSGk1/qJK/YSV6Jk8IyF0nRobSNj6xY/DCC+Ci7trioA9QtVQOFGxGRxsMwDPYdLeGH9KOs2XOUFbsOsyPnzFp+AIKsFqwWsFrMjU2jw4KJCQ8hNsL8My4ihPhIO02j7MRH2omPspPkCKVppJ0gjRPyCYWbGijciIg0bjn5pazYdZgVOw9zuKgcR1gwMRXdZWEhQRzILWXXoUJ2Hyoi40gxnnP4LWmzWkisWP25eUwYLZqY6wO1iDFfITYrhgGVtwgLDiI+SoGoOgo3NVC4ERGR01XmcpNf4sJjmKs+uz3mys95JU6OFpeTW+w0B0gXlXGooJxDhWUcLCzjYEEZOQVluM8iGQUHWbyLJLaICSM2wk50mM27G3zzmFB6tozBFtS4NknVgGIREREfsNuCiI86u5lWLreHg4VlHMgtJTPPXLV5/9ES9h09tiGq22NgsViwAFiguNyN022w97A5c+xkokNtDO0Qz0UdExjWMR6rxUJWXinZBaXk5Jfi8hi0bRpJamIkcREhjW7MkFpuRERE6giX20N2QRn7jhR7Q1BuceVu8Oag55+yCzhaXP10+erEhAfTLj6SiJ/tBO9yeygqc1FYdmxQdvOYMDo3i6JLs2i6NI+mfXwkjvBg7LbAT6VXt1QNFG5ERKQ+c3sM1mfksigth4VpOWzeb26JERcRQkJ0KEnR5mbROw8WkXG0GF/8lrfbrERXjEtKiLLTPCbMfDlCSYi2ExZsIywkiLBg8xUZaq5C7UsKNzVQuBERkYakoNSJ3RZEiO3EMTgl5W7v4Ohyl6fKuSCrhUi7jfAQG5F2G/ZgK3sPF7P1QD5bMyvWFzrLcNSzpYNP7jz/bL9StTTmRkREpJGICg0+6bmwkCC6NnfQtbnjtK7VITGKS7oket97PAaF5S5vl1heiZPs/FIO5JayP7eEzNwSDhaWUer0UFLuptRpdm+FhQS2G0vhRkRERKpltVqIDg0mOjSYlk1O/3OB7hRqXPPIREREpNYFenaWwo2IiIg0KAo3IiIi0qAo3IiIiEiDonAjIiIiDYrCjYiIiDQoCjciIiLSoCjciIiISIOicCMiIiINisKNiIiINCgKNyIiItKgKNyIiIhIg6JwIyIiIg2Kwo2IiIg0KLZAV8DfKrdhz8/PD3BNRERE5HRV/t6u/D1ek0YXbgoKCgBITk4OcE1ERETkTBUUFOBwOGosYzFOJwI1IB6PhwMHDhAVFYXFYvHptfPz80lOTiYjI4Po6GifXluO0XP2Dz1n/9Bz9h89a/+oredsGAYFBQU0b94cq7XmUTWNruXGarXSsmXLWr1HdHS0/sPxAz1n/9Bz9g89Z//Rs/aP2njOp2qxqaQBxSIiItKgKNyIiIhIg6Jw40N2u51//OMf2O32QFelQdNz9g89Z//Qc/YfPWv/qAvPudENKBYREZGGTS03IiIi0qAo3IiIiEiDonAjIiIiDYrCjYiIiDQoCjc+8uKLL9K6dWtCQ0M577zz+P777wNdpTpt2rRp9O/fn6ioKBISEhgzZgxpaWlVypSWlnLHHXcQFxdHZGQkv/rVr8jOzq5SJj09nVGjRhEeHk5CQgJ//vOfcblcVcosWrSIPn36YLfbad++PTNmzKjtr1cnPf7441gsFu6++27vMT1j39m/fz/XX389cXFxhIWF0b17d9asWeM9bxgGDzzwAM2aNSMsLIzhw4ezffv2Ktc4cuQIEyZMIDo6mpiYGCZPnkxhYWGVMhs3buSCCy4gNDSU5ORknnzySb98v7rA7Xbz97//nTZt2hAWFka7du145JFHquw1pOd85pYsWcIVV1xB8+bNsVgsfPzxx1XO+/OZzp49m06dOhEaGkr37t358ssvz+5LGXLOZs2aZYSEhBhvvPGGsWXLFuPmm282YmJijOzs7EBXrc4aMWKE8eabbxqbN2821q9fb1x++eVGSkqKUVhY6C1z6623GsnJycaCBQuMNWvWGAMHDjQGDx7sPe9yuYxu3boZw4cPN9atW2d8+eWXRtOmTY2pU6d6y+zatcsIDw83/vjHPxpbt241XnjhBSMoKMj4+uuv/fp9A+377783WrdubfTo0cOYMmWK97iesW8cOXLEaNWqlXHjjTcaq1atMnbt2mXMnTvX2LFjh7fM448/bjgcDuPjjz82NmzYYFx55ZVGmzZtjJKSEm+ZkSNHGj179jRWrlxpfPfdd0b79u2N8ePHe8/n5eUZiYmJxoQJE4zNmzcb7733nhEWFma88sorfv2+gfLoo48acXFxxueff27s3r3bmD17thEZGWk899xz3jJ6zmfuyy+/NO677z7jo48+MgBjzpw5Vc7765kuW7bMCAoKMp588klj69atxv33328EBwcbmzZtOuPvpHDjAwMGDDDuuOMO73u32200b97cmDZtWgBrVb/k5OQYgLF48WLDMAwjNzfXCA4ONmbPnu0ts23bNgMwVqxYYRiG+R+k1Wo1srKyvGVeeuklIzo62igrKzMMwzD+8pe/GF27dq1yr3HjxhkjRoyo7a9UZxQUFBipqanGvHnzjGHDhnnDjZ6x79x7773G+eeff9LzHo/HSEpKMp566invsdzcXMNutxvvvfeeYRiGsXXrVgMwVq9e7S3z1VdfGRaLxdi/f79hGIbxf//3f0aTJk28z77y3h07dvT1V6qTRo0aZdx0001Vjl111VXGhAkTDMPQc/aFn4cbfz7Ta6+91hg1alSV+px33nnG7373uzP+HuqWOkfl5eWsXbuW4cOHe49ZrVaGDx/OihUrAliz+iUvLw+A2NhYANauXYvT6azyXDt16kRKSor3ua5YsYLu3buTmJjoLTNixAjy8/PZsmWLt8zx16gs05j+bu644w5GjRp1wnPQM/adTz/9lH79+nHNNdeQkJBA7969ee2117znd+/eTVZWVpXn5HA4OO+886o865iYGPr16+ctM3z4cKxWK6tWrfKWGTp0KCEhId4yI0aMIC0tjaNHj9b21wy4wYMHs2DBAn766ScANmzYwNKlS7nssssAPefa4M9n6st/SxRuztGhQ4dwu91V/vEHSExMJCsrK0C1ql88Hg933303Q4YMoVu3bgBkZWUREhJCTExMlbLHP9esrKxqn3vluZrK5OfnU1JSUhtfp06ZNWsWP/zwA9OmTTvhnJ6x7+zatYuXXnqJ1NRU5s6dy2233cbvf/973nrrLeDYs6rp34msrCwSEhKqnLfZbMTGxp7R30dD9te//pVf//rXdOrUieDgYHr37s3dd9/NhAkTAD3n2uDPZ3qyMmfzzBvdruBS99xxxx1s3ryZpUuXBroqDUpGRgZTpkxh3rx5hIaGBro6DZrH46Ffv3489thjAPTu3ZvNmzfz8ssvM2nSpADXruH44IMPePfdd5k5cyZdu3Zl/fr13H333TRv3lzPWapQy805atq0KUFBQSfMMMnOziYpKSlAtao/7rzzTj7//HMWLlxIy5YtvceTkpIoLy8nNze3Svnjn2tSUlK1z73yXE1loqOjCQsL8/XXqVPWrl1LTk4Offr0wWazYbPZWLx4Mc8//zw2m43ExEQ9Yx9p1qwZXbp0qXKsc+fOpKenA8eeVU3/TiQlJZGTk1PlvMvl4siRI2f099GQ/fnPf/a23nTv3p0bbriBP/zhD96WST1n3/PnMz1ZmbN55go35ygkJIS+ffuyYMEC7zGPx8OCBQsYNGhQAGtWtxmGwZ133smcOXP49ttvadOmTZXzffv2JTg4uMpzTUtLIz093ftcBw0axKZNm6r8RzVv3jyio6O9v2gGDRpU5RqVZRrD383FF1/Mpk2bWL9+vffVr18/JkyY4P1Zz9g3hgwZcsJSBj/99BOtWrUCoE2bNiQlJVV5Tvn5+axatarKs87NzWXt2rXeMt9++y0ej4fzzjvPW2bJkiU4nU5vmXnz5tGxY0eaNGlSa9+vriguLsZqrfprKygoCI/HA+g51wZ/PlOf/ltyxkOQ5QSzZs0y7Ha7MWPGDGPr1q3GLbfcYsTExFSZYSJV3XbbbYbD4TAWLVpkZGZmel/FxcXeMrfeequRkpJifPvtt8aaNWuMQYMGGYMGDfKer5ymfOmllxrr1683vv76ayM+Pr7aacp//vOfjW3bthkvvvhio5umfLzjZ0sZhp6xr3z//feGzWYzHn30UWP79u3Gu+++a4SHhxv//e9/vWUef/xxIyYmxvjkk0+MjRs3GqNHj652Om3v3r2NVatWGUuXLjVSU1OrTKfNzc01EhMTjRtuuMHYvHmzMWvWLCM8PLzBTlH+uUmTJhktWrTwTgX/6KOPjKZNmxp/+ctfvGX0nM9cQUGBsW7dOmPdunUGYDzzzDPGunXrjL179xqG4b9numzZMsNmsxlPP/20sW3bNuMf//iHpoIH2gsvvGCkpKQYISEhxoABA4yVK1cGukp1GlDt68033/SWKSkpMW6//XajSZMmRnh4uDF27FgjMzOzynX27NljXHbZZUZYWJjRtGlT409/+pPhdDqrlFm4cKHRq1cvIyQkxGjbtm2VezQ2Pw83esa+89lnnxndunUz7Ha70alTJ+PVV1+tct7j8Rh///vfjcTERMNutxsXX3yxkZaWVqXM4cOHjfHjxxuRkZFGdHS08Zvf/MYoKCioUmbDhg3G+eefb9jtdqNFixbG448/Xuvfra7Iz883pkyZYqSkpBihoaFG27Ztjfvuu6/K9GI95zO3cOHCav89njRpkmEY/n2mH3zwgdGhQwcjJCTE6Nq1q/HFF1+c1XeyGMZxSzuKiIiI1HMacyMiIiINisKNiIiINCgKNyIiItKgKNyIiIhIg6JwIyIiIg2Kwo2IiIg0KAo3IiIi0qAo3IiIiEiDonAjIrWudevWPPvss6ddftGiRVgslhM29RQROR0KNyLiZbFYanw9+OCDZ3Xd1atXc8stt5x2+cGDB5OZmYnD4Tir+52J1157jZ49exIZGUlMTAy9e/f27jINcOONNzJmzJhar4eI+I4t0BUQkbojMzPT+/P777/PAw88UGW368jISO/PhmHgdrux2U79z0h8fPwZ1SMkJISkpKQz+szZeOONN7j77rt5/vnnGTZsGGVlZWzcuJHNmzfX+r1FpPao5UZEvJKSkrwvh8OBxWLxvv/xxx+Jioriq6++om/fvtjtdpYuXcrOnTsZPXo0iYmJREZG0r9/f+bPn1/luj/vlrJYLLz++uuMHTuW8PBwUlNT+fTTT73nf94tNWPGDGJiYpg7dy6dO3cmMjKSkSNHVgljLpeL3//+98TExBAXF8e9997LpEmTamx1+fTTT7n22muZPHky7du3p2vXrowfP55HH30UgAcffJC33nqLTz75xNt6tWjRIgAyMjK49tpriYmJITY2ltGjR7Nnzx7vtStbfB566CHi4+OJjo7m1ltvpby83Fvmww8/pHv37oSFhREXF8fw4cMpKio6w781Efk5hRsROSN//etfefzxx9m2bRs9evSgsLCQyy+/nAULFrBu3TpGjhzJFVdcQXp6eo3Xeeihh7j22mvZuHEjl19+ORMmTODIkSMnLV9cXMzTTz/NO++8w5IlS0hPT+eee+7xnn/iiSd49913efPNN1m2bBn5+fl8/PHHNdYhKSmJlStXsnfv3mrP33PPPVx77bXeIJWZmcngwYNxOp2MGDGCqKgovvvuO5YtW+YNXMeHlwULFrBt2zYWLVrEe++9x0cffcRDDz0EmK1k48eP56abbvKWueqqq9BexiI+cFZ7iYtIg/fmm28aDofD+37hwoUGYHz88cen/GzXrl2NF154wfu+VatWxr///W/ve8C4//77ve8LCwsNwPjqq6+q3Ovo0aPeugDGjh07vJ958cUXjcTERO/7xMRE46mnnvK+d7lcRkpKijF69OiT1vPAgQPGwIEDDcDo0KGDMWnSJOP999833G63t8ykSZNOuMY777xjdOzY0fB4PN5jZWVlRlhYmDF37lzv52JjY42ioiJvmZdeesmIjIw03G63sXbtWgMw9uzZc9L6icjZUcuNiJyRfv36VXlfWFjIPffcQ+fOnYmJiSEyMpJt27adsuWmR48e3p8jIiKIjo4mJyfnpOXDw8Np166d932zZs285fPy8sjOzmbAgAHe80FBQfTt27fGOjRr1owVK1awadMmpkyZgsvlYtKkSYwcORKPx3PSz23YsIEdO3YQFRVFZGQkkZGRxMbGUlpays6dO73levbsSXh4uPf9oEGDKCwsJCMjg549e3LxxRfTvXt3rrnmGl577TWOHj1aY31F5PRoQLGInJGIiIgq7++55x7mzZvH008/Tfv27QkLC+Pqq6+u0j1TneDg4CrvLRZLjYGiuvKGj7pwunXrRrdu3bj99tu59dZbueCCC1i8eDEXXXRRteULCwvp27cv77777gnnTnfwdFBQEPPmzWP58uV88803vPDCC9x3332sWrWKNm3anNP3EWns1HIjIudk2bJl3HjjjYwdO5bu3buTlJRUZWCtPzgcDhITE1m9erX3mNvt5ocffjjja3Xp0gXAO7A3JCQEt9tdpUyfPn3Yvn07CQkJtG/fvsrr+OnrGzZsoKSkxPt+5cqVREZGkpycDJgBbciQITz00EOsW7eOkJAQ5syZc8Z1FpGqFG5E5Jykpqby0UcfsX79ejZs2MB1111XYwtMbbnrrruYNm0an3zyCWlpaUyZMoWjR49isVhO+pnbbruNRx55hGXLlrF3715WrlzJxIkTiY+PZ9CgQYA502vjxo2kpaVx6NAhnE4nEyZMoGnTpowePZrvvvuO3bt3s2jRIn7/+9+zb98+7/XLy8uZPHkyW7du5csvv+Qf//gHd955J1arlVWrVvHYY4+xZs0a0tPT+eijjzh48CCdO3eu9Wcl0tAp3IjIOXnmmWdo0qQJgwcP5oorrmDEiBH06dPH7/W49957GT9+PBMnTmTQoEFERkYyYsQIQkNDT/qZ4cOHs3LlSq655ho6dOjAr371K0JDQ1mwYAFxcXEA3HzzzXTs2JF+/foRHx/PsmXLCA8PZ8mSJaSkpHDVVVfRuXNnJk+eTGlpKdHR0d7rX3zxxaSmpjJ06FDGjRvHlVde6V0IMTo6miVLlnD55ZfToUMH7r//fv71r39x2WWX1epzEmkMLIavOq1FROoQj8dD586dufbaa3nkkUf8fv8bb7yR3NzcU05HFxHf04BiEWkQ9u7dyzfffONdaXj69Ons3r2b6667LtBVExE/U7eUiDQIVquVGTNm0L9/f4YMGcKmTZuYP3++xrCINELqlhIREZEGRS03IiIi0qAo3IiIiEiDonAjIiIiDYrCjYiIiDQoCjciIiLSoCjciIiISIOicCMiIiINisKNiIiINCj/D7VQiVpHP+ztAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot losses\n",
    "df = pd.DataFrame(loss_data)\n",
    "df = df.drop([df[df.step == 7500].index[0], df[df.step == 5000].index[0]]) # Drop the first record on resuming, else we will have 5000 and 5001 both\n",
    "plt.plot(df['step'], df['train_loss'])\n",
    "plt.plot(df['step'], df['val_loss'])\n",
    "plt.xlabel('Training Steps')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Training', 'Validation'], loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "eaff78c9-f39d-47ff-b733-71910eedb5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save loss data\n",
    "with open('losses.pkl','wb') as f:\n",
    "    pkl.dump(loss_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "6d87dacb-0e90-4030-bf21-73d3fc994f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wouldst he fair of in this laster'd birds,--\n",
      "\n",
      "PRIStETER:\n",
      "Thou knows town the trumphants one served\n",
      "What I make at about reptience in on queen;\n",
      "Shall light in once needs though the herebs,\n",
      "Could be confort thee: bry with me fin all walf,\n",
      "Take thou, ere we grant down thee hents,\n",
      "And bid Ithe the cause enjorn taken tee\n",
      "hore place they some of the wronch; when left angue,\n",
      "But weep the freely to city charge:\n",
      "There Clifford's speed, alas, and becomend severight,\n",
      "Which this by mine a three to the worst.\n",
      "\n",
      "VALET:\n",
      "Alack, lord.\n",
      "\n",
      "BUCKINGHAM:\n",
      "Then busines down?\n",
      "Mark thou shad for the pirace,\n",
      "The feary operfice I see at will slend\n",
      "And the senate, go is that a condauses\n",
      "in that Maristake thee come to my queen!\n",
      "\n",
      "KING RICHARD II:\n",
      "Who young foranot you and may me now we in merry,\n",
      "Upon the guard instatily: bear livs hee, me lets\n",
      "To hath been and onceivil age and the sabsed owe bird,\n",
      "Who can all them before as hour, return, pity were to me\n",
      "His sile kindly father 'Doles and the vown:\n",
      "And news shall quarrel\n"
     ]
    }
   ],
   "source": [
    "# Test generation\n",
    "gen = model.generate(torch.zeros((1,1), dtype=torch.long, device=device), 1000)\n",
    "print(decode(gen[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "fdec3bb2-14be-4088-9e23-361fbd812f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "And will my rasy; condem'd lie thee sensite\n",
      "Of promperying look upon upon.\n",
      "Helpinage good to the graftere;\n",
      "\n",
      "GLOUCESTER:\n",
      "None consin in, or let to justic it your day\n",
      "When they are asleep-wachmen his poor\n",
      "Burging a king: when here it is a the tides\n",
      "Would drink to the point, next with thy state:\n",
      "And be seen your we both 'gainst your wates; rather all\n",
      "And more no with the life that daught from my lord.\n",
      "\n",
      "KING HENRY VITHORK:\n",
      "It not the ciupand's each off miish?\n",
      "\n",
      "DUKESS OF YORK:\n",
      "And what thou never sadom?\n",
      "\n",
      "VOLUMNIA:\n",
      "Too.\n",
      "\n",
      "YORK:\n",
      "AI will so the such of not or speedishy soul!\n",
      "\n",
      "Citizens:\n",
      "If thee to not leave them I bury, and his like,\n",
      "To this cricks from drops with not be reful die.\n",
      "\n",
      "DUCHESS OF YORK:\n",
      "Honow I would yea, here consul find notel.\n",
      "\n",
      "KING HENRY VI\n",
      "\n",
      "GLOUCESTER:\n",
      "What now you are these with days, ere this\n",
      "but on the busines and the ose unto him,\n",
      "Than an thee misjoy tended, servey your horse.\n",
      "\n",
      "Servant:\n",
      "It is, all summuch bove a loss in again,\n",
      "Smew let their to gatest, been with her like,\n",
      "Th\n"
     ]
    }
   ],
   "source": [
    "# Test generation\n",
    "gen = model.generate(torch.zeros((1,1), dtype=torch.long, device=device), 1000)\n",
    "print(decode(gen[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f169212-8bd2-4b3d-ab53-fa26d171c447",
   "metadata": {},
   "source": [
    "#### Test Generations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c002d3d6-99bb-45d2-af8f-c305f6d9ff52",
   "metadata": {},
   "source": [
    "These are generation tests at different points during dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "810f71c3-9b5b-41b0-809f-c62a44b84325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 101])\n",
      "\n",
      "Reacou'gr te thand tibary fachary aCafh't thaifu Casnoumt mldyou I cance-snOe allatry, M: owin fi ur\n"
     ]
    }
   ],
   "source": [
    "# Test generation\n",
    "gen = model.generate(torch.zeros((1,1), dtype=torch.long, device=device), 100)\n",
    "print(gen.shape)\n",
    "print(decode(gen[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0cca9d09-5ca5-4fd2-b52c-75db2a8e6a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 101])\n",
      "\n",
      "co y ind deiced tlat manginsigesps\n",
      "Selthangean th url sat ghe mt machan tHe.\n",
      "e\n",
      "N dFind wisthurore ce\n"
     ]
    }
   ],
   "source": [
    "# Test generation\n",
    "gen = model.generate(torch.zeros((1,1), dtype=torch.long, device=device), 100)\n",
    "print(gen.shape)\n",
    "print(decode(gen[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "761caca1-50e4-40b1-beba-3d0c010d7e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 101])\n",
      "\n",
      "QUSTEGSUK:\n",
      "HakNy Ebd I theollds:\n",
      "Do with syounty ther whath crist bUllnginy tard.\n",
      "\n",
      "\n",
      "QUCUEESHERY Lom;\n"
     ]
    }
   ],
   "source": [
    "# Test generation\n",
    "gen = model.generate(torch.zeros((1,1), dtype=torch.long, device=device), 100)\n",
    "print(gen.shape)\n",
    "print(decode(gen[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "c80a690e-69a7-4c69-8d7d-91cd744944be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ho ting My I:\n",
      "ward god have kis,\n",
      "Wow,\n",
      "Hrerit, worsth\n",
      "Thing luor heng tholeil mecow hund End.\n",
      "CENLIAS\n"
     ]
    }
   ],
   "source": [
    "# Test generation\n",
    "gen = model.generate(torch.zeros((1,1), dtype=torch.long, device=device), 100)\n",
    "print(decode(gen[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "875286a4-fe6d-4030-81d9-3c783396de5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "gidine were my har death the consins\n",
      "Romeon these would play dest with their friend.\n",
      "\n",
      "Serdard:\n",
      "Why; Wenry have happing, make in deed the was\n",
      "That youth, dowy in beg list hime -havous tialte,\n",
      "To some h\n"
     ]
    }
   ],
   "source": [
    "# Test generation\n",
    "gen = model.generate(torch.zeros((1,1), dtype=torch.long, device=device), 200)\n",
    "print(decode(gen[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "6c3bf01a-fa42-40aa-bcc2-bd45895a217d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "And they see met, to bring the life; I\n",
      "And with stand way.\n",
      "\n",
      "MERCUTIO:\n",
      "Two of the good! this dost me; your lord bed,\n",
      "For all wait to hear, answer than hand,\n",
      "But when raster woulds the way we who weep?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test generation\n",
    "gen = model.generate(torch.zeros((1,1), dtype=torch.long, device=device), 200)\n",
    "print(decode(gen[0].tolist()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
